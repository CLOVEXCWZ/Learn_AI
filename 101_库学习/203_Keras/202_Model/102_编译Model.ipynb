{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译Model\n",
    "\n",
    "**索引**\n",
    "- 代码展示\n",
    "- 损失函数\n",
    "- 优化器\n",
    "- 评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CL-Dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this returen a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.name = \"CL-Dense\"\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数\n",
    "\n",
    "- mean_squared_error\n",
    "    - mean_squared_error(y_true, y_pred)\n",
    "- mean_absolute_error\n",
    "    - mean_absolute_error(y_true, y_pred)\n",
    "- mean_absolute_percentage_error\n",
    "    - mean_absolute_percentage_error(y_true, y_pred)\n",
    "- mean_squared_logarithmic_error\n",
    "    - mean_squared_logarithmic_error(y_true, y_pred)\n",
    "- squared_hinge\n",
    "    - squared_hinge(y_true, y_pred)\n",
    "- hinge\n",
    "    - hinge(y_true, y_pred)\n",
    "- categorical_hinge\n",
    "    - categorical_hinge(y_true, y_pred)\n",
    "- logcosh\n",
    "    - logcosh(y_true, y_pred)\n",
    "- categorical_crossentropy\n",
    "    - categorical_crossentropy(y_true, y_pred)\n",
    "- sparse_categorical_crossentropy\n",
    "    - sparse_categorical_crossentropy(y_true, y_pred)\n",
    "- binary_crossentropy\n",
    "    - binary_crossentropy(y_true, y_pred)\n",
    "- kullback_leibler_divergence\n",
    "    - kullback_leibler_divergence(y_true, y_pred)\n",
    "- poisson\n",
    "    - poisson(y_true, y_pred)\n",
    "- cosine_proximity\n",
    "    - cosine_proximity(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 函数Keras实现\n",
    "# 未经过验证(手抄)\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import six\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "\n",
    "\n",
    "# 均方误差\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# 平均绝对误差\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred, y_true), axis=-1)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, t_pred):\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 100. * K.mean(diff, axis=-1)\n",
    "\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.mean(K.square(first_log - second_log), axis=-1)\n",
    "\n",
    "def squared_hinge(y_true, y_pred):\n",
    "    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)\n",
    "\n",
    "def hinge(y_true, y_pred):\n",
    "    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)\n",
    "\n",
    "def categorical_hinge(y_true, y_pred):\n",
    "    pos = K.sum(y_true * y_pred, axis=-1)\n",
    "    neg = K.max((1. - y_true) * y_pred, axis=-1)\n",
    "    return K.maximum(0., neg - pos + 1.)\n",
    "\n",
    "def logcosh(y_true, y_pred):\n",
    "    \"\"\"Logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "    `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n",
    "    to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n",
    "    like the mean squared error, but will not be so strongly affected by the\n",
    "    occasional wildly incorrect prediction.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: tensor of true targets.\n",
    "        y_pred: tensor of predicted targets.\n",
    "\n",
    "    # Returns\n",
    "        Tensor with one scalar loss entry per sample.\n",
    "    \"\"\"\n",
    "    def _logcosh(x):\n",
    "        return x + K.softplus(-2. * x) - K.log(2.)\n",
    "    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n",
    "\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    return K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "def kullback_leibler_divergence(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n",
    "\n",
    "def poisson(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n",
    "\n",
    "def cosine_proximity(y_true, y_pred):\n",
    "    y_true = K.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
    "    return -K.sum(y_true * y_pred, axis=-1)\n",
    "\n",
    "mse = MSE = mean_squared_error\n",
    "mae = MAE = mean_absolute_error\n",
    "mape = MAPE = mean_absolute_percentage_error\n",
    "msle = MSLE = mean_squared_logarithmic_error\n",
    "kld = KLD = kullback_leibler_divergence\n",
    "cosine = cosine_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化器\n",
    "\n",
    "- sgd \n",
    "    - SGD\n",
    "- rmsprop \n",
    "    - RMSprop\n",
    "- adagrad \n",
    "    - Adagrad\n",
    "- adadelta \n",
    "    - Adadelta\n",
    "- adam \n",
    "    - Adam\n",
    "- adamax \n",
    "    - Adamax\n",
    "- nadam \n",
    "    - Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评价函数\n",
    "- binary_accuracy\n",
    "    - binary_accuracy(y_true, y_pred)\n",
    "- categorical_accuracy\n",
    "    - categorical_accuracy(y_true, y_pred)\n",
    "- sparse_categorical_accuracy\n",
    "    - sparse_categorical_accuracy(y_true, y_pred)\n",
    "- top_k_categorical_accuracy\n",
    "    - top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "- sparse_top_k_categorical_accuracy\n",
    "    - sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "    \n",
    "**从loss引入的**\n",
    "- mse = MSE = mean_squared_error\n",
    "- mae = MAE = mean_absolute_error\n",
    "- mape = MAPE = mean_absolute_percentage_error\n",
    "- msle = MSLE = mean_squared_logarithmic_error\n",
    "- cosine = cosine_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
