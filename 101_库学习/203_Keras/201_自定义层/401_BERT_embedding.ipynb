{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT embedding 层抄写 (未验证)\n",
    "\n",
    "目的\n",
    "\n",
    "- 理解keras层的编写\n",
    "- 理解bert的构成\n",
    "- 培养能更改、编辑 层的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras_pos_embd import PositionEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(keras.layers.Embedding):\n",
    "    \"\"\" Embedding 同时返回 weights参数 \"\"\"\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" 由于在返回Embedding的同时还需要返回参数weights 所以在返回原来shahe的同时还需要返回 weight的shape \"\"\"\n",
    "        return [super(TokenEmbedding, self).compute_output_shape(input_shape), (self.input_dim, self.output_dim)]\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return [super(TokenEmbedding, self).compute_mask(inputs, mask), None]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # 返回 embedding 的同时返回weights\n",
    "        # K.identity 返回与输入张量相同的张量\n",
    "        return [super(TokenEmbedding, self).call(inputs), K.identity(self.embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(inputs, token_num, pos_num, embed_dim, dropout_rate=0.1, trainable=True):\n",
    "    \"\"\" 获取embedding层\n",
    "    See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "    \n",
    "    :param inputs：输入层(bert网络会有3个输入 [token_input, segment_input, masked_input] )\n",
    "    :param token_num: token的数量(一般vocab size)\n",
    "    :param pos_num: 位置数量(句子长度， 默认为512)\n",
    "    :param embed_dim: 编码dim维度 （每一个词的向量长度，默认为512）\n",
    "    :param dropout_rate: dropout比例\n",
    "    :param trainable: 是否为可训练\n",
    "    :return: embedding后的层 和 weight参数\n",
    "    \"\"\"\n",
    "    \n",
    "    # embeddings = [[token_embedding, token_weights], segment_embedding]\n",
    "    embeddings = [\n",
    "        TokenEmbedding(\n",
    "            input_dim=token_dim,\n",
    "            output_dim=embed_dim,\n",
    "            mask_zero=True,\n",
    "            trainable=trainable,\n",
    "            name=\"Embedding-Token\",\n",
    "        )(inputs[0]),\n",
    "        keras.layers.Embedding(\n",
    "            input_dim=2,\n",
    "            output_dim=embed_dim,\n",
    "            trainable=trainable,\n",
    "            name=\"Embedding-Segment\",\n",
    "        )(inputs[1])\n",
    "    ]\n",
    "    \n",
    "    # embeddings[0], embed_weights = [token_embedding, token_weights]\n",
    "    embeddings[0], embed_weights = embeddings[0]\n",
    "    # 两层相加 toekn_embedding、segment_embedding\n",
    "    embed_layer = keras.layers.Add(name=\"Embedding-Token-Segment\")(embeddings)\n",
    "    # 进行 PositionEmbedding (位置编码)\n",
    "    embed_layer = PostionEmbedding(\n",
    "        input_dim=pos_num,\n",
    "        output_dim=embed_dim,\n",
    "        mode=PositionEmbedding.MODE_ADD,\n",
    "        trainable=trainable,\n",
    "        name='Embedding-Position',\n",
    "    )(embed_layer)\n",
    "    return embed_layer, embed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingSimilarity(keras.layers.Layer):\n",
    "    \"\"\" 计算特征和toekn embeddings的相似度 \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 initializer='zeros',\n",
    "                 regularizer=None,\n",
    "                 constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\" 初始化 layer\n",
    "        \n",
    "        :param output_dim: Same as embedding output dimension.\n",
    "        :param initializer: Initializer for bias.\n",
    "        :param regularizer: Regularizer for bias.\n",
    "        :param constraint: Constraint for bias.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(EmbeddingSimilarity, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "        self.regularizer = keras.regularizers.get(regularizer)\n",
    "        self.constraint = keras.constraints.get(constraint)\n",
    "        self.bias = None\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'initializer': keras.initializers.serialize(self.initializer),\n",
    "            'regularizer': keras.regularizers.serialize(self.regularizer),\n",
    "            'constraint': keras.constraints.serialize(self.constraint),\n",
    "        }\n",
    "        base_config = super(EmbeddingSimilarity, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\" Bert网络这个层为两个输入 \"\"\"\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(int(input_shape[1][0])),\n",
    "            initializer=self.initializer,\n",
    "            regularizer=self.regularizer,\n",
    "            constraint=self.constraint,\n",
    "            name='bias',\n",
    "        )\n",
    "        super(EmbeddingSimilarity, self).build(input_shape)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"  Bert网络输入一把为 (Lr(None, 512, 768 ), weight(30000, 768))\n",
    "        所以输出为: (None, 512, 30000)\n",
    "        \"\"\"\n",
    "        return input_shape[0][:2] + (input_shape[1][0])\n",
    "    \n",
    "    def comput_mask(self, inputs, mask=None):\n",
    "        return mask[0]\n",
    "    \n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        # Bert网络输入一把为 (LN(None, 512, 768 ), weight(30000, 768))\n",
    "        # inputs, embeddings = (LN(None, 512, 768 ), weight(30000, 768))\n",
    "        inputs, embeddings = inputs\n",
    "        # outputs = LN * weight + b  ======== (None, 512, 768)*(768, 30000) -> (None, 512, 30000)\n",
    "        outputs = K.bias_add(K.dot(inputs, K.transpose(embeddings)), self.bias)\n",
    "        return keras.activations.softmax(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "- 来自: keras_embed_sim -> embeddings\n",
    "- keras_embed_sim是一个库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingRet(keras.layers.Embedding):\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [\n",
    "            super(EmbeddingRet, slef).compute_output_shape(input_shape),\n",
    "            (self.input_dim, self.output_dim),\n",
    "        ]\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return [\n",
    "            super(EmbeddingRet, self).compute_mask(inputs, mask),\n",
    "            None,\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return [\n",
    "            super(EmbeddingRet, self).call(inputs),\n",
    "            K.identity(self.embeddings),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingSim(keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 use_bias=True,\n",
    "                 initializer='zeros',\n",
    "                 regularizer=None,\n",
    "                 constraint=None,\n",
    "                 stop_gradient=False,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \"\"\"Initialize the layer.\n",
    "\n",
    "        :param output_dim: Same as embedding output dimension.\n",
    "        :param use_bias: Whether to use bias term.\n",
    "        :param initializer: Initializer for bias.\n",
    "        :param regularizer: Regularizer for bias.\n",
    "        :param constraint: Constraint for bias.\n",
    "        :param stop_gradient: Whether to stop gradient for input embedding.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(EmbeddingSim, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.use_bias = use_bias\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "        self.regularizer = keras.regularizers.get(regularizer)\n",
    "        self.constraint = keras.constraints.get(constraint)\n",
    "        self.stop_gradient = stop_gradient\n",
    "        self.bias = None\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'use_bias': self.use_bias,\n",
    "            'initializer': keras.initializers.serialize(self.initializer),\n",
    "            'regularizer': keras.regularizers.serialize(self.regularizer),\n",
    "            'constraint': keras.constraints.serialize(self.constraint),\n",
    "            'stop_gradient': self.stop_gradient,\n",
    "        }\n",
    "        base_config = super(EmbeddingSim, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self.bias:\n",
    "            embed_shape = input_shape[1]\n",
    "            token_num = int(embed_shape[0])\n",
    "            self.bais = self.add_weight( \n",
    "                shape=(token_num,),\n",
    "                initializer=self.initializer,\n",
    "                regularizer=self.regularizer,\n",
    "                constraint=self.constraint,\n",
    "                name='bias',\n",
    "            )\n",
    "        super(EmbeddingSim, self).build(input_shape)          \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        feature_shape, embed_shape = input_shape\n",
    "        token_num = embed_shape[0]\n",
    "        return feature_shape[:-1] + (token_num,)\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        return mask[0]\n",
    "    \n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        inputs, embeddings = inputs\n",
    "        if self.stop_gradient:\n",
    "            embeddings = K.stop_gradient(embeddings)\n",
    "        outputs = K.dot(inputs, K.transpose(embeddings))\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(outputs, self.bias)\n",
    "        return keras.activations.softmax(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras Embedding\n",
    "- 源码中的Embedding\n",
    "\n",
    "- 略有修改(主要是import的原因)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 embeddings_initializer='uniform',\n",
    "                 embeddings_regularizer=None,\n",
    "                 activaity_regularizer=None,\n",
    "                 embedding_constranint=None,\n",
    "                 mask_zero=False,\n",
    "                 input_length=None,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        if 'input_shape' not in kwargs:\n",
    "            if input_length:\n",
    "                kwargs['input_shape'] = (input_lenght,)\n",
    "            else:\n",
    "                kwargs['input_shape'] = (None,)\n",
    "        super(Embedding, self).__init__(**kwargs)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embeddings_initializer = keras.initializers.get(embeddings_initializer)\n",
    "        self.embeddings_regularizer = keras.regularizers.get(embeddings_regularizer)\n",
    "        self.activaity_regularizer = keras.regularizers.get(activaity_regularizer)\n",
    "        self.embeddings_constraint = keras.constraints.get(embeddings_constraint)\n",
    "        self.mask_zero = mask_zero\n",
    "        self.supports = mask_zero\n",
    "        self.input_length = input_length\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "            shape=(self.input_dim, self.output_dim),\n",
    "            initializer=self.embeddings_initializer,\n",
    "            constraint=self.embeddings_regularizer,\n",
    "            dtype=self.dtype\n",
    "        )\n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if not self.mask_zero:\n",
    "            return None\n",
    "        output_mask = K.not_equal(inputs, 0)\n",
    "        return output_mask\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # 这个方法没怎么弄懂的=======\n",
    "        if self.input_length is None:\n",
    "            return input_shape + (self.output_dim,)\n",
    "        else:\n",
    "            # input_length can be tuple if input is 3D or higher\n",
    "            if isinstance(self.input_length, (list, tuple)):\n",
    "                in_lens = list(self.input_length)\n",
    "            else:\n",
    "                in_lens = [self.input_length]\n",
    "            if len(in_lens) != len(input_shape) - 1:\n",
    "                ValueError('\"input_length\" is %s, but received input has shape %s' %\n",
    "                           (str(self.input_length), str(input_shape)))\n",
    "            else:\n",
    "                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n",
    "                    if s1 is not None and s2 is not None and s1 != s2:\n",
    "                        ValueError('\"input_length\" is %s, but received input has shape %s' %\n",
    "                                   (str(self.input_length), str(input_shape)))\n",
    "                    elif s1 is None:\n",
    "                        in_lens[i] = s2\n",
    "            return (input_shape[0],) + tuple(in_lens) + (self.output_dim,)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        if K.dtype(inputs) != 'int32':\n",
    "            inputs = K.cast(inputs, 'int32')\n",
    "        out = K.gather(self.embeddings, inputs)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'input_dim': self.input_dim,\n",
    "                  'output_dim': self.output_dim,\n",
    "                  'embeddings_initializer': initializers.serialize(self.embeddings_initializer),\n",
    "                  'embeddings_regularizer': regularizers.serialize(self.embeddings_regularizer),\n",
    "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "                  'embeddings_constraint': constraints.serialize(self.embeddings_constraint),\n",
    "                  'mask_zero': self.mask_zero,\n",
    "                  'input_length': self.input_length}\n",
    "        base_config = super(Embedding, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
