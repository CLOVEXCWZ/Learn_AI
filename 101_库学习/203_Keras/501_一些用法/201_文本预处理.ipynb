{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**文本预处理**\n",
    "\n",
    "- 句子分割text_to_word_sequence\n",
    "- one-hot编码 \n",
    "- 分词器Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 句子分割text_to_word_sequence\n",
    "\n",
    "\n",
    "```python\n",
    "keras.preprocessing.text.text_to_word_sequence(text,\n",
    "                                               filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
    "                                               lower=True,\n",
    "                                               split=\" \")\n",
    "```\n",
    "\n",
    "- text：字符串，待处理的文本\n",
    "- filters：需要滤除的字符的列表或连接形成的字符串，例如标点符号。默认值为 '!\"#$%&()*+,-./:;<=>?@[]^_`{|}~\\t\\n'，包含标点符号，制表符和换行符等\n",
    "- lower：布尔值，是否将序列设为小写形式\n",
    "- split：字符串，单词的分隔符，如空格\n",
    "                                               \n",
    "**返回值**\n",
    "- 字符串列表                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['near',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'name',\n",
       " 'you',\n",
       " 'should',\n",
       " 'always',\n",
       " 'be',\n",
       " 'near',\n",
       " 'to',\n",
       " 'someone',\n",
       " 'to',\n",
       " 'save']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence = 'Near is a good name, you should always be near to someone to save'\n",
    "text_to_word_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你是人间四月天', '是的']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "你是人间四月天\n",
    "是的\n",
    "\"\"\"\n",
    "text_to_word_sequence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 one-hot编码\n",
    "\n",
    "```python\n",
    "keras.preprocessing.text.one_hot(text,\n",
    "                                 n,\n",
    "                                 filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
    "                                 lower=True,\n",
    "                                 split=\" \")\n",
    "                                 \n",
    "```\n",
    "参数\n",
    "\n",
    "n：整数，字典长度\n",
    "返回值\n",
    "\n",
    "整数列表，每个整数是[1,n]之间的值，代表一个单词（不保证唯一性，即如果词典长度不够，不同的单词可能会被编为同一个码）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 9, 9, 17, 5, 19, 4, 15, 6, 2, 16, 2, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "sentence = 'Near is a good name, you should always be near to someone to save'\n",
    "one_hot(sentence, n=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 16, 1, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "sentence = \"\"\"\n",
    "你是人间四月天\n",
    "是的\n",
    "不是吧\n",
    "恩\n",
    "\"\"\"\n",
    "one_hot(sentence, n=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tokenizer\n",
    "\n",
    "```python\n",
    "keras.preprocessing.text.Tokenizer(num_words=None,\n",
    "                                   filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,\n",
    "                                   split=\" \",\n",
    "                                   char_level=False)\n",
    "```\n",
    "\n",
    "\n",
    "构造参数\n",
    "\n",
    "与text_to_word_sequence同名参数含义相同\n",
    "- num_words：None或整数，处理的最大单词数量。若被设置为整数，则分词器将被限制为待处理数据集中最常见的num_words个单词\n",
    "- char_level: 如果为 True, 每个字符将被视为一个标记\n",
    "类方法\n",
    "\n",
    "- fit_on_texts(texts)\n",
    "    - texts：要用以训练的文本列表\n",
    "- texts_to_sequences(texts)\n",
    "    - texts：待转为序列的文本列表\n",
    "    - 返回值：序列的列表，列表中每个序列对应于一段输入文本\n",
    "    \n",
    "- texts_to_sequences_generator(texts)\n",
    "    - 本函数是texts_to_sequences的生成器函数版\n",
    "    - texts：待转为序列的文本列表\n",
    "    - 返回值：每次调用返回对应于一段输入文本的序列\n",
    "- texts_to_matrix(texts, mode)：\n",
    "    - texts：待向量化的文本列表\n",
    "    - mode：‘binary’，‘count’，‘tfidf’，‘freq’之一，默认为‘binary’\n",
    "    - 返回值：形如(len(texts), nb_words)的numpy array\n",
    "- fit_on_sequences(sequences):\n",
    "    - sequences：要用以训练的序列列表\n",
    "- sequences_to_matrix(sequences):\n",
    "    - sequences：待向量化的序列列表\n",
    "    - mode：‘binary’，‘count’，‘tfidf’，‘freq’之一，默认为‘binary’\n",
    "    - 返回值：形如(len(sequences), nb_words)的numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok.word_counts:OrderedDict([('i', 2), ('am', 2), ('kira', 1), ('the', 2), ('lord', 1), ('of', 1), ('new', 1), ('world', 1)])\n",
      "tok.word_docs:defaultdict(<class 'int'>, {'am': 2, 'i': 2, 'kira': 1, 'lord': 1, 'the': 1, 'of': 1, 'world': 1, 'new': 1})\n",
      "tok.word_index:{'i': 1, 'am': 2, 'the': 3, 'kira': 4, 'lord': 5, 'of': 6, 'new': 7, 'world': 8}\n",
      "tok.document_count:2\n",
      "tok.texts_to_matrix(text):[[0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentence1 = 'I am kira'\n",
    "sentence2 = 'I am the Lord of the new world'\n",
    "text = [sentence1,sentence2]\n",
    "\n",
    "tok = Tokenizer(num_words=None)\n",
    "tok.fit_on_texts(text)\n",
    "# print tok attributes\n",
    "print(f\"tok.word_counts:{tok.word_counts}\") # 每个word出现了几次\n",
    "print(f\"tok.word_docs:{tok.word_docs}\") # 每个word出现在几个文档中\n",
    "print(f\"tok.word_index:{tok.word_index}\") # 每个word对应的index，字典映射\n",
    "print(f\"tok.document_count:{tok.document_count}\") # 一共有多少文档\n",
    "# print vectorized text\n",
    "print(f\"tok.texts_to_matrix(text):{tok.texts_to_matrix(text)}\") # 返回一个【文档数×num_words】的mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
