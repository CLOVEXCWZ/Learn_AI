{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "######HyperParameter\n",
    "train_step = 20\n",
    "batch_size = 100\n",
    "fc_hidden1 = 120\n",
    "fc_hidden2 = 84\n",
    "lr = 0.1\n",
    "\n",
    "#construct graph######################\n",
    "x_batch = tf.placeholder(tf.float32,shape=[None,28,28,1],name=\"x_batch\")\n",
    "y_batch = tf.placeholder(tf.float32,shape=[None,10],name=\"y_batch\")\n",
    "\n",
    "####conv layer###################\n",
    "def add_conv_layer(input,in_size,out_size,k_size,k_strides,activation_func=None):\n",
    "    \n",
    "#     W = tf.Variable(tf.truncated_normal(shape= [k_size, k_size, in_channel, out_channel], stddev = 0.1))\n",
    "#     b = tf.Variable(tf.constant(0.1, shape=[out_channel]))\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal(shape=[k_size,k_size,in_size,out_size], stddev = 0.1),name=\"W_conv\")\n",
    "    b = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[out_size]),name=\"b_conv\")\n",
    "    \n",
    "    \n",
    "#     W = tf.Variable(tf.truncated_normal(shape=[k_size,k_size,in_size,out_size]),name=\"W_conv\")\n",
    "#     b = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[out_size]),name=\"b_conv\")\n",
    "    \n",
    "    xW_plus_b = tf.nn.conv2d(input,W,strides=[1,k_strides,k_strides,1],padding=\"SAME\") + b\n",
    "    if activation_func is None:\n",
    "        return  xW_plus_b\n",
    "    else:\n",
    "        return activation_func(xW_plus_b)\n",
    "\n",
    "#####pool layer##################\n",
    "def add_pool_layer(input,k_size,k_strides,activation_func=None):\n",
    "    return tf.nn.max_pool(input,ksize=[1,k_size,k_size,1],strides=[1,k_strides,k_strides,1],padding=\"SAME\")\n",
    "\n",
    "#####fully connectly layer##################\n",
    "def add_fc_layer(input,in_size,out_size,activation_func=None):\n",
    "    \n",
    "#     W = tf.Variable(tf.truncated_normal(shape = [in_size, out_size], stddev = 0.1))\n",
    "#     b = tf.Variable(tf.constant(0.1, shape = [out_size]))\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal(shape=[in_size,out_size], stddev = 0.1),name=\"W_fc\")\n",
    "    b = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[out_size]),name=\"b_fc\")\n",
    "    \n",
    "    \n",
    "#     W = tf.Variable(tf.truncated_normal(shape=[in_size,out_size]),name=\"W_fc\")\n",
    "#     b = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[out_size]),name=\"b_fc\")\n",
    "    \n",
    "    \n",
    "    xW_plus_b = tf.matmul(input,W) + b\n",
    "    if activation_func is None:\n",
    "        return xW_plus_b\n",
    "    else:\n",
    "        return activation_func(xW_plus_b)\n",
    "\n",
    "#####conv1_op##################\n",
    "conv1 = add_conv_layer(x_batch,1,32,3,1,activation_func=tf.nn.relu)\n",
    "#conv1[None,28,28,32]\n",
    "#####pool1_op##################\n",
    "pool1 = add_pool_layer(conv1,2,2,activation_func=None)\n",
    "#pool1[None,14,14,32]\n",
    "######conv2_op#################\n",
    "conv2 = add_conv_layer(pool1,32,64,3,1,activation_func=tf.nn.relu)\n",
    "#conv2[None,14,14,64]\n",
    "######pool2_op#################\n",
    "pool2 = add_pool_layer(conv2,2,2)\n",
    "#pool2[None,7,7,64]\n",
    "######flatten#################\n",
    "flatten = tf.reshape(pool2,shape=[-1,7*7*64],name=\"input_flatten\")\n",
    "######fully1 connectly_op################\n",
    "fc1 = add_fc_layer(flatten,7*7*64,fc_hidden1,tf.nn.relu)\n",
    "######fully2 connectly_op################\n",
    "fc2 = add_fc_layer(fc1,fc_hidden1,fc_hidden2,tf.nn.relu)\n",
    "######output_op################\n",
    "output = add_fc_layer(fc2,fc_hidden2,10)\n",
    "#######accuracy###################\n",
    "pred = tf.nn.softmax(output)\n",
    "equal_data = tf.equal(tf.argmax(pred,axis=1),tf.argmax(y_batch,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(equal_data,dtype=tf.float32))\n",
    "######loss_op################\n",
    "loss = tf.losses.softmax_cross_entropy(y_batch,output)\n",
    "######train_op################\n",
    "train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "######init_op################\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "mnist_base_path=\"/Users/zhouwencheng/Desktop/Grass/data/picture/mnist\"\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(mnist_base_path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 loss:  0.08737619 accuracy:  0.9718\n",
      "step:  1 loss:  0.072331876 accuracy:  0.9771\n",
      "step:  2 loss:  0.053904884 accuracy:  0.9828\n",
      "step:  3 loss:  0.0432497 accuracy:  0.9858\n",
      "step:  4 loss:  0.04030357 accuracy:  0.9855\n",
      "step:  5 loss:  0.03683272 accuracy:  0.9869\n",
      "step:  6 loss:  0.036150172 accuracy:  0.9876\n",
      "step:  7 loss:  0.037228893 accuracy:  0.9874\n",
      "step:  8 loss:  0.038176075 accuracy:  0.9876\n",
      "step:  9 loss:  0.033081263 accuracy:  0.9897\n",
      "step:  10 loss:  0.03585591 accuracy:  0.9882\n",
      "step:  11 loss:  0.040684145 accuracy:  0.988\n",
      "step:  12 loss:  0.03651812 accuracy:  0.9889\n",
      "step:  13 loss:  0.03705407 accuracy:  0.9893\n",
      "step:  14 loss:  0.040960394 accuracy:  0.9885\n",
      "step:  15 loss:  0.036979143 accuracy:  0.9897\n",
      "step:  16 loss:  0.036929823 accuracy:  0.9893\n",
      "step:  17 loss:  0.038664453 accuracy:  0.9892\n",
      "step:  18 loss:  0.048693977 accuracy:  0.9876\n",
      "step:  19 loss:  0.03860829 accuracy:  0.9905\n"
     ]
    }
   ],
   "source": [
    "######executer graph################\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(train_step):\n",
    "        total_batch = int(mnist.train.num_examples // batch_size)\n",
    "        for one_batch in range(total_batch):\n",
    "            x_train,y_train=mnist.train.next_batch(batch_size)\n",
    "            x_flatten_train = x_train.reshape([batch_size,28,28,1])\n",
    "            sess.run(train_op,feed_dict={x_batch:x_flatten_train,y_batch:y_train})\n",
    "\n",
    "        x_test,y_test = mnist.test.next_batch(10000)\n",
    "        x_flatten_test = x_test.reshape([10000,28,28,1])\n",
    "        acc,output_value = sess.run([accuracy,loss],feed_dict={x_batch:x_flatten_test,y_batch:y_test})\n",
    "        print(\"step: \",i,\"loss: \",output_value,\"accuracy: \",acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "step:  0 loss:  0.08737619 accuracy:  0.9718\n",
    "step:  1 loss:  0.072331876 accuracy:  0.9771\n",
    "step:  2 loss:  0.053904884 accuracy:  0.9828\n",
    "step:  3 loss:  0.0432497 accuracy:  0.9858\n",
    "step:  4 loss:  0.04030357 accuracy:  0.9855\n",
    "step:  5 loss:  0.03683272 accuracy:  0.9869\n",
    "step:  6 loss:  0.036150172 accuracy:  0.9876\n",
    "step:  7 loss:  0.037228893 accuracy:  0.9874\n",
    "step:  8 loss:  0.038176075 accuracy:  0.9876\n",
    "step:  9 loss:  0.033081263 accuracy:  0.9897\n",
    "step:  10 loss:  0.03585591 accuracy:  0.9882\n",
    "step:  11 loss:  0.040684145 accuracy:  0.988\n",
    "step:  12 loss:  0.03651812 accuracy:  0.9889\n",
    "step:  13 loss:  0.03705407 accuracy:  0.9893\n",
    "step:  14 loss:  0.040960394 accuracy:  0.9885\n",
    "step:  15 loss:  0.036979143 accuracy:  0.9897\n",
    "step:  16 loss:  0.036929823 accuracy:  0.9893\n",
    "step:  17 loss:  0.038664453 accuracy:  0.9892\n",
    "step:  18 loss:  0.048693977 accuracy:  0.9876\n",
    "step:  19 loss:  0.03860829 accuracy:  0.9905"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
