{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-11å±‚\n",
    "\n",
    "- padding  same\n",
    "\n",
    "- img  224 x 224\n",
    "- conv_1 f_64 k_3x3  s_1x1    => 224x224x64\n",
    "- pool_1  k_2x2  s_2x2          => 112x112x64\n",
    "\n",
    "- conv_2 f_128 k_3x3  s_1x1    => 112x112x128\n",
    "- pool_2  k_2x2  s_2x2           => 56x56x128\n",
    "\n",
    "- conv_3 f_256 k_3x3  s_1x1    => 56x56x256\n",
    "- conv_4 f_256 k_3x3  s_1x1    => 56x56x256\n",
    "- pool_3  k_2x2  s_2x2           => 28x28x256\n",
    "\n",
    "- conv_5 f_512 k_3x3  s_1x1    => 28x38x512\n",
    "- conv_6 f_512 k_3x3  s_1x1    => 38x38x512\n",
    "- pool_3  k_2x2  s_2x2           => 14x14x512\n",
    "\n",
    "- conv_7 f_512 k_3x3  s_1x1    => 14x14x512\n",
    "- conv_8 f_512 k_3x3  s_1x1    => 14x14x512\n",
    "- pool_3  k_2x2  s_2x2           => 7x7x512\n",
    "\n",
    "- dense_9  in_25088 out_4096 => 4096\n",
    "- dense_10 in_4096 out_4096 => 4096\n",
    "- dense_11 in_4096 out_1000 => 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5436"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picture224x224_base_path=\"/Users/zhouwencheng/Desktop/Grass/data/picture/picture224x224\"\n",
    "path_train_base = picture224x224_base_path + \"/train/\"\n",
    "path_test_base = picture224x224_base_path + \"/test/\"\n",
    "\n",
    "df_train = pd.read_csv(path_train_base + 'list.csv', index_col=0)\n",
    "df_test = pd.read_csv(path_test_base + 'list.csv', index_col=0)\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217_10.png</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179_17.png</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204_4.png</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118_1.png</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>079_5.png</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  label\n",
       "0  217_10.png    217\n",
       "1  179_17.png    179\n",
       "2   204_4.png    204\n",
       "3   118_1.png    118\n",
       "4   079_5.png     79"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315_9.png</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295_13.png</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222_7.png</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345_18.png</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>077_12.png</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  label\n",
       "0   315_9.png    315\n",
       "1  295_13.png    295\n",
       "2   222_7.png    222\n",
       "3  345_18.png    345\n",
       "4  077_12.png     77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readImg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "for name in df_train.name:\n",
    "    path = path_train_base + name\n",
    "    img = plt.imread(path).ravel()\n",
    "    x_train.append(img)\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readImg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_test = []\n",
    "for name in df_test.name:\n",
    "    path = path_test_base + name\n",
    "    img = plt.imread(path).ravel()\n",
    "    x_test.append(img)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5436, 50176)\n",
      "(1651, 50176)\n",
      "(5436,)\n",
      "(1651,)\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train.label.values\n",
    "y_test = df_test.label.values\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(y_train.reshape([-1, 1]))\n",
    "y_train_one = enc.transform(y_train.reshape([-1, 1]))\n",
    "y_test_one = enc.transform(y_test.reshape([-1, 1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_batch(x_data, n_batch, batch_size):\n",
    "    len_train = len(x_data)\n",
    "    total_batch = len_train // batch_size\n",
    "    if total_batch%batch_size > 0:\n",
    "        total_batch += 1 \n",
    "    get_batch = n_batch%total_batch\n",
    "    first_index = get_batch * batch_size\n",
    "    last_index = get_batch*batch_size + batch_size\n",
    "    if last_index > len_train:\n",
    "        last_index = len_train\n",
    "    return x_data[first_index: last_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_type = 386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 224*224])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, img_type])\n",
    "\n",
    "x_flat = tf.reshape(x, shape=[-1, 224, 224, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-e9455370e826>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-13-e9455370e826>:2: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-e9455370e826>:21: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-e9455370e826>:22: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "conv_1 = tf.layers.conv2d(inputs=x_flat, filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "pool_1 = tf.layers.max_pooling2d(inputs=conv_1, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "conv_2 = tf.layers.conv2d(inputs=pool_1, filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "pool_2 = tf.layers.max_pooling2d(inputs=conv_2, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "conv_3 = tf.layers.conv2d(inputs=pool_2, filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "conv_4 = tf.layers.conv2d(inputs=conv_3, filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "pool_3 = tf.layers.max_pooling2d(inputs=conv_4, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "conv_5 = tf.layers.conv2d(inputs=pool_3, filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "conv_6 = tf.layers.conv2d(inputs=conv_5, filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "pool_4 = tf.layers.max_pooling2d(inputs=conv_6, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "conv_7 = tf.layers.conv2d(inputs=pool_4, filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "conv_8 = tf.layers.conv2d(inputs=conv_7, filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same',activation=tf.nn.relu)\n",
    "pool_5 = tf.layers.max_pooling2d(inputs=conv_8, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "pool_5_flat = tf.reshape(pool_5, shape=[-1, 7*7*512])\n",
    "\n",
    "dense_1 = tf.layers.dense(pool_5_flat, 1024, activation=tf.nn.relu)\n",
    "dense_1 = tf.nn.dropout(dense_1, keep_prob=0.5)\n",
    "dense_2 = tf.layers.dense(dense_1, 1024, activation=tf.nn.relu)\n",
    "dense_2 = tf.nn.dropout(dense_2, keep_prob=0.5)\n",
    "prediction = tf.layers.dense(dense_2, img_type , activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-3a0cb1b82b9a>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(x=tf.math.argmax(y, 1), y=tf.math.argmax(prediction, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch: (100, 50176)\n",
      "y_batch: (100, 386)\n"
     ]
    }
   ],
   "source": [
    "x_batch = data_batch(x_train, n_batch=0, batch_size=100)\n",
    "y_batch = data_batch(y_train_one, n_batch=0, batch_size=100)\n",
    "print(\"x_batch:\", x_batch.shape)\n",
    "print(\"y_batch:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BG\n",
      "WARNING:tensorflow:From /Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from save/660/LeNet.ckpt\n",
      "step: 0 loss: 5.9502788 accuracy: 0.01\n",
      "step: 0 loss: 5.96028 accuracy: 0.0\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.96028 accuracy: 0.0\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n",
      "step: 0 loss: 5.95028 accuracy: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"BG\") \n",
    "\n",
    "to_saver = tf.train.Saver()  \n",
    "\n",
    "with tf.Session() as sess:  \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.import_meta_graph('save/660/LeNet.ckpt.meta')\n",
    "    if saver:\n",
    "        saver.restore(sess, 'save/660/LeNet.ckpt') \n",
    "    \n",
    "    for step in range(100): \n",
    "        for batch in range(100):\n",
    "            x_batch = data_batch(x_train, n_batch=batch, batch_size=100)\n",
    "            y_batch = data_batch(y_train_one, n_batch=batch, batch_size=100)\n",
    "            sess.run(train, feed_dict = {x:x_batch, y:y_batch})\n",
    "            \n",
    "#             print(\"x_batch:\", x_batch.shape)\n",
    "#             print(\"y_batch:\", y_batch.shape)\n",
    "             \n",
    "            x_test_batch = data_batch(x_test, n_batch=0, batch_size=100)\n",
    "            y_test_batch = data_batch(y_test_one, n_batch=0, batch_size=100)\n",
    "            \n",
    "            this_loss, acc = sess.run([loss, accuracy], feed_dict = {x:x_test_batch, y:y_test_batch})\n",
    "            print('step:', step, 'loss:', this_loss, 'accuracy:', acc)  \n",
    "            to_saver.save(sess, \"save/660/LeNet.ckpt\")\n",
    "        \n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
