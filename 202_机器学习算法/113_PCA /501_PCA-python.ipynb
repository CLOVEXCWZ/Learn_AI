{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/u012162613/article/details/42177327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 算法步骤\n",
    "- 零均值化\n",
    "- 求协方差矩阵\n",
    "- 求特征值、特征矩阵\n",
    "- 保留主要成分[即保留值比较大的前n个特征]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96388791]\n",
      " [ 3.0069765 ]\n",
      " [-2.0430886 ]]\n",
      "[1.66666667 4.33333333 5.         7.33333333 7.66666667]\n",
      "[[-0.28887379]\n",
      " [ 0.21257931]\n",
      " [-0.3570162 ]\n",
      " [-0.1444369 ]\n",
      " [-0.85031722]]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def zero_mean(data_mat):\n",
    "    \"\"\"\n",
    "    零均值化\n",
    "    \"\"\"\n",
    "    mean_val = np.mean(data_mat, axis = 0) #按列求均值，即求各个特征的均值\n",
    "    new_data = data_mat - mean_val\n",
    "    return new_data, mean_val\n",
    "\n",
    "def pca(data_mat, n):\n",
    "    new_data, mean_val = zero_mean(data_mat)\n",
    "    cov_mat = np.cov(new_data, rowvar = 0)  #求协方差矩阵,return ndarray；若rowvar非0，一列代表一个样本，为0，一行代表一个样本\n",
    "    \n",
    "    eig_vlas, eig_vects = np.linalg.eig(np.mat(cov_mat)) #求特征值和特征向量,特征向量是按列放的，即一列代表一个特征向量\n",
    "    eig_val_indice = np.argsort(eig_vlas) #对特征值从小到大排序\n",
    "    n_eig_val_indice=eig_val_indice[-1:-(n+1):-1]   #最大的n个特征值的下标( [::-1]是逆序的意思)\n",
    "    n_eig_vects = eig_vects[:,n_eig_val_indice] #最大的n个特征值对应的特征向量\n",
    "    low_data_mat=new_data*n_eig_vects               #低维特征空间的数据(点乘)\n",
    "    recon_mat = (low_data_mat * n_eig_vects.T) + mean_val #重构数据\n",
    "    return low_data_mat, recon_mat   \n",
    "     \n",
    "     \n",
    "\n",
    "a = np.array([\n",
    "    [1, 4, 5, 7, 9],\n",
    "    [1, 5, 4, 7, 5],\n",
    "    [3, 4, 6, 8, 9]\n",
    "])\n",
    "\n",
    "l1, l2 = pca(a, 1)\n",
    "print(l1)\n",
    "print(l2) \n",
    " \n",
    "\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择主成分个数\n",
    "    文章写到这里还没有完，应用PCA的时候，对于一个1000维的数据，我们怎么知道要降到几维的数据才是合理的？即n要取多少，才能保留最多信息同时去除最多的噪声？一般，我们是通过方差百分比来确定n的，这一点在Ufldl教程中说得很清楚，并且有一条简单的公式，下面是该公式的截图：\n",
    "   ![301](picture/301.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96388791]\n",
      " [ 3.0069765 ]\n",
      " [-2.0430886 ]]\n",
      "[[1.94510862 4.12843071 5.3441236  7.47255431 8.48627716]\n",
      " [0.79802995 4.97255431 3.92646067 6.89901498 5.10978275]\n",
      " [2.25686142 3.89901498 5.72941573 7.62843071 9.40394009]]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def zero_mean(data_mat):\n",
    "    \"\"\"\n",
    "    零均值化\n",
    "    \"\"\"\n",
    "    mean_val = np.mean(data_mat, axis = 0) #按列求均值，即求各个特征的均值\n",
    "    new_data = data_mat - mean_val\n",
    "    return new_data, mean_val\n",
    "\n",
    "def percentage2n(eig_vals, percentage):\n",
    "    sort_array = np.sort(eig_vals)   #升序\n",
    "    sort_array = sort_array[-1::-1]  #逆转，即降序\n",
    "    array_sum = sum(sort_array)\n",
    "    \n",
    "    tmp_sum = 0\n",
    "    num = 0\n",
    "    for item in sort_array:\n",
    "        tmp_sum += item\n",
    "        num += 1\n",
    "        if tmp_sum >= array_sum*percentage:\n",
    "            return num\n",
    "    return num\n",
    "\n",
    "def pcaa(data_mat, percen_tage=0.99):\n",
    "    new_data, mean_val = zero_mean(data_mat)\n",
    "    cov_mat = np.cov(new_data, rowvar = 0)  #求协方差矩阵,return ndarray；若rowvar非0，一列代表一个样本，为0，一行代表一个样本\n",
    "    \n",
    "    eig_vlas, eig_vects = np.linalg.eig(np.mat(cov_mat)) #求特征值和特征向量,特征向量是按列放的，即一列代表一个特征向量\n",
    "    eig_val_indice = np.argsort(eig_vlas) #对特征值从小到大排序\n",
    "    \n",
    "    n = percentage2n(eig_vlas, percen_tage)\n",
    "    \n",
    "    n_eig_val_indice=eig_val_indice[-1:-(n+1):-1]   #最大的n个特征值的下标( [::-1]是逆序的意思)\n",
    "    n_eig_vects = eig_vects[:,n_eig_val_indice] #最大的n个特征值对应的特征向量\n",
    "    low_data_mat=new_data*n_eig_vects               #低维特征空间的数据(点乘)\n",
    "    recon_mat = (low_data_mat * n_eig_vects.T) + mean_val #重构数据\n",
    "    return low_data_mat, recon_mat  \n",
    "\n",
    "a = np.array([\n",
    "    [1, 4, 5, 7, 9],\n",
    "    [1, 5, 4, 7, 5],\n",
    "    [3, 4, 6, 8, 9]\n",
    "])\n",
    "\n",
    "l1, l2 = pcaa(a, 0.5)\n",
    "print(l1)\n",
    "print(l2) \n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96388805]\n",
      " [ 3.0069766 ]\n",
      " [-2.043089  ]]\n",
      "[[1.6666666 4.3333335 5.        7.3333335 7.6666665]]\n",
      "[[-0.2888738 ]\n",
      " [ 0.21257932]\n",
      " [-0.35701624]\n",
      " [-0.1444369 ]\n",
      " [-0.85031724]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#定义PCA算法               \n",
    "def PCA(data,r):\n",
    "    data=np.float32(np.mat(data))\n",
    "    rows,cols=np.shape(data)\n",
    "    data_mean=np.mean(data,0)#对列求平均值\n",
    "    A=data-np.tile(data_mean,(rows,1))#将所有样例减去对应均值得到A\n",
    "    C=A*A.T #得到协方差矩阵\n",
    "    D,V=np.linalg.eig(C)#求协方差矩阵的特征值和特征向量 \n",
    "    V_r=V[:,0:r]      # 按列取前r个特征向量\n",
    "    V_r=A.T*V_r#小矩阵特征向量向大矩阵特征向量过渡\n",
    "    for i in range(r):\n",
    "        V_r[:,i]=V_r[:,i]/np.linalg.norm(V_r[:,i])#特征向量归一化\n",
    "    \n",
    "    final_data=A*V_r\n",
    "    return final_data,data_mean,V_r\n",
    "\n",
    "\n",
    "a = np.array([\n",
    "    [1, 4, 5, 7, 9],\n",
    "    [1, 5, 4, 7, 5],\n",
    "    [3, 4, 6, 8, 9]\n",
    "])\n",
    "\n",
    "l1, l2, l3 = PCA(a, 1)\n",
    "print(l1)\n",
    "print(l2)\n",
    "print(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
