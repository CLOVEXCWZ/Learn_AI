{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于序列标注的思路对对联。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "maxlen = 16\n",
    "batch_size = 64\n",
    "char_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(txt_name):\n",
    "    text = codecs.open(txt_name, encoding='utf-8').read()\n",
    "    text = text.strip().split('\\n')\n",
    "    text = [l.strip().split(' ') for l in text]\n",
    "    text = [l for l in text if len(l) <= maxlen] # 删除过长的对联\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_base_path=\"/Users/zhouwencheng/Desktop/Grass/data/txt/couplet\"\n",
    "train_x_path=couplet_base_path+\"/train/in.txt\"\n",
    "train_y_path=couplet_base_path+\"/train/out.txt\"\n",
    "test_x_path=couplet_base_path+\"/test/in.txt\"\n",
    "test_y_path=couplet_base_path+\"/test/out.txt\"\n",
    "\n",
    "x_train_txt = read_data(train_x_path)\n",
    "y_train_txt = read_data(train_y_path)\n",
    "x_test_txt = read_data(test_x_path)\n",
    "y_test_txt = read_data(test_y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = {}\n",
    "for txt in [x_train_txt, y_train_txt, x_test_txt, y_test_txt]:\n",
    "    for l in txt:\n",
    "        for w in l:\n",
    "            chars[w] = chars.get(w, 0) + 1\n",
    "chars = {i:j for i,j in chars.items() if j >= min_count}\n",
    "id2char = {i+1:j for i,j in enumerate(chars)}\n",
    "char2id = {j:i for i,j in id2char.items()}\n",
    "\n",
    "def string2id(s):\n",
    "    # 0: <unk>\n",
    "    return [char2id.get(c, 0) for c in s]\n",
    "\n",
    "x_train = list(map(string2id, x_train_txt))\n",
    "y_train = list(map(string2id, y_train_txt))\n",
    "x_test = list(map(string2id, x_test_txt))\n",
    "y_test = list(map(string2id, y_test_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 按字数分组存放\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for i,x in enumerate(x_train):\n",
    "    j = len(x)\n",
    "    if j not in train_dict:\n",
    "        train_dict[j] = [[], []]\n",
    "    train_dict[j][0].append(x)\n",
    "    train_dict[j][1].append(y_train[i])\n",
    "    \n",
    "for i,x in enumerate(x_test):\n",
    "    j = len(x)\n",
    "    if j not in test_dict:\n",
    "        test_dict[j] = [[], []]\n",
    "    test_dict[j][0].append(x)\n",
    "    test_dict[j][1].append(y_test[i])\n",
    "\n",
    "for j in train_dict:\n",
    "    train_dict[j][0] = np.array(train_dict[j][0])\n",
    "    train_dict[j][1] = np.array(train_dict[j][1])\n",
    "\n",
    "for j in test_dict:\n",
    "    test_dict[j][0] = np.array(test_dict[j][0])\n",
    "    test_dict[j][1] = np.array(test_dict[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data):\n",
    "    data_p = [float(len(i[0])) for i in data.values()]\n",
    "    data_p = np.array(data_p) / sum(data_p)\n",
    "    while True: # 随机选一个字数，然后随机选样本，生成字数一样的一个batch\n",
    "        idx = np.random.choice(len(data_p), p=data_p) + 1\n",
    "        size = min(batch_size, len(data[idx][0]))\n",
    "        idxs = np.random.choice(len(data[idx][0]), size=size)\n",
    "        np.random.shuffle(idxs)\n",
    "        yield data[idx][0][idxs], np.expand_dims(data[idx][1][idxs], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gated_resnet(x, ksize=3):\n",
    "    # 门卷积 + 残差\n",
    "    x_dim = K.int_shape(x)[-1]\n",
    "    xo = Conv1D(x_dim*2, ksize, padding='same')(x)\n",
    "    return Lambda(lambda x: x[0] * K.sigmoid(x[1][..., :x_dim]) \\\n",
    "                            + x[1][..., x_dim:] * K.sigmoid(-x[1][..., :x_dim]))([x, xo])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    945408      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 128)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    98560       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 128)    0           dropout_2[0][0]                  \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    98560       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 128)    0           lambda_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    98560       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 128)    0           lambda_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    98560       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 128)    0           lambda_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    98560       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, 128)    0           lambda_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    98560       lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, None, 128)    0           lambda_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 7386)   952794      lambda_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,489,562\n",
      "Trainable params: 2,489,562\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_in = Input(shape=(None,))\n",
    "x = x_in\n",
    "x = Embedding(len(chars)+1, char_size)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = gated_resnet(x)\n",
    "x = gated_resnet(x)\n",
    "x = gated_resnet(x)\n",
    "x = gated_resnet(x)\n",
    "x = gated_resnet(x)\n",
    "x = gated_resnet(x)\n",
    "\n",
    "x = Dense(len(chars)+1, activation='softmax')(x)\n",
    "\n",
    "model = Model(x_in, x)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import handlers\n",
    " \n",
    "class Logger(object):\n",
    "    level_relations = {\n",
    "        'debug':logging.DEBUG,\n",
    "        'info':logging.INFO,\n",
    "        'warning':logging.WARNING,\n",
    "        'error':logging.ERROR,\n",
    "        'crit':logging.CRITICAL\n",
    "    }#日志级别关系映射\n",
    " \n",
    "    def __init__(self,filename,level='info',when='D',backCount=3,fmt='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'):\n",
    "        self.logger = logging.getLogger(filename)\n",
    "        format_str = logging.Formatter(fmt)#设置日志格式\n",
    "        self.logger.setLevel(self.level_relations.get(level))#设置日志级别 \n",
    "        th = handlers.TimedRotatingFileHandler(filename=filename,when=when,backupCount=backCount,encoding='utf-8')#往文件里写入#指定间隔时间自动生成文件的处理器\n",
    "        #实例化TimedRotatingFileHandler\n",
    "        #interval是时间间隔，backupCount是备份文件的个数，如果超过这个个数，就会自动删除，when是间隔的时间单位，单位有以下几种：\n",
    "        # S 秒 M 分  H 小时、 D 天、 W 每星期（interval==0时代表星期一）\n",
    "        # midnight 每天凌晨\n",
    "        th.setFormatter(format_str)#设置文件里写入的格式 \n",
    "        self.logger.addHandler(th)\n",
    "# if __name__ == '__main__':\n",
    "#     log = Logger('all.log',level='debug')\n",
    "#     log.logger.debug('debug')\n",
    "#     log.logger.info('info')\n",
    "#     log.logger.warning('警告')\n",
    "#     log.logger.error('报错')\n",
    "#     log.logger.critical('严重') \n",
    "\n",
    "log = Logger('log/501_couplet.log',level='debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couplet_match(s):\n",
    "    # 输出对联\n",
    "    # 先验知识：跟上联同一位置的字不能一样\n",
    "    x = np.array([string2id(s)])\n",
    "    y = model.predict(x)[0]\n",
    "    for i,j in enumerate(x[0]):\n",
    "        y[i, j] = 0.\n",
    "    y = y[:, 1:].argmax(axis=1) + 1\n",
    "    r = ''.join([id2char[i] for i in y])\n",
    "    print(u'上联：%s，下联：%s' % (s, r))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"/Users/zhouwencheng/Desktop/Grass/data/model/102_s2s_keras/501_couplet\"+\"/c_d_couplet.h5\"\n",
    "import logging\n",
    "# 通过下面的方式进行简单配置输出方式与日志级别\n",
    "logging.basicConfig(filename='log/501_couplet.log', level=logging.INFO)\n",
    "\n",
    "class Evaluate(Callback):\n",
    "    def __init__(self):\n",
    "        self.lowest = 1e10\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log.logger.info(couplet_match(u'晚风摇树树还挺'))\n",
    "        log.logger.info(couplet_match(u'今天天气不错'))\n",
    "        log.logger.info(couplet_match(u'鱼跃此时海'))\n",
    "        log.logger.info(couplet_match(u'只有香如故')) \n",
    "        # 保存最优结果\n",
    "        if logs['val_loss'] <= self.lowest:\n",
    "            self.lowest = logs['val_loss'] \n",
    "            log.logger.info(\"val_loss:\"+str(self.lowest)) \n",
    "            model.save(save_path)\n",
    "            log.logger.info(\"save model at:\"+save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouwencheng/Desktop/Grass/101PythonEnv/envpy3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 3.2945 - val_loss: 5.4835\n",
      "上联：晚风摇树树还挺，下联：明雨醉风风不飞\n",
      "上联：今天天气不错，下联：大月国人无明\n",
      "上联：鱼跃此时海，下联：鸟飞一处人\n",
      "上联：只有香如故，下联：能无月似春\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 3.2467 - val_loss: 14.6239\n",
      "上联：晚风摇树树还挺，下联：春雨落花花不浓\n",
      "上联：今天天气不错，下联：古海人人无明\n",
      "上联：鱼跃此时海，下联：花开其处人\n",
      "上联：只有香如故，下联：无无道不新\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 3.0644 - val_loss: 6.7358\n",
      "上联：晚风摇树树还挺，下联：秋雨照花山不闲\n",
      "上联：今天天气不错，下联：大地国人无明\n",
      "上联：鱼跃此时海，下联：花开一处人\n",
      "上联：只有香如故，下联：方无月不新\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 3.0145 - val_loss: 5.9018\n",
      "上联：晚风摇树树还挺，下联：寒雨照花花不深\n",
      "上联：今天天气不错，下联：此地人人无清\n",
      "上联：鱼跃此时海，下联：马开万处人\n",
      "上联：只有香如故，下联：何无月若天\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 3.0057 - val_loss: 5.4665\n",
      "上联：晚风摇树树还挺，下联：春雨落花花不浓\n",
      "上联：今天天气不错，下联：大地月人无清\n",
      "上联：鱼跃此时海，下联：鸟开一处人\n",
      "上联：只有香如故，下联：何无月不春\n",
      "Epoch 6/100\n",
      " 748/1000 [=====================>........] - ETA: 39s - loss: 2.9731"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "if os.path.exists(save_path):\n",
    "    model = load_model(save_path)\n",
    "\n",
    "evaluator = Evaluate()\n",
    "model.fit_generator(data_generator(train_dict),\n",
    "                    steps_per_epoch=1000,\n",
    "                    epochs=100,\n",
    "                    validation_data=data_generator(test_dict),\n",
    "                    validation_steps=100,\n",
    "                    callbacks=[evaluator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import handlers\n",
    " \n",
    "class Logger(object):\n",
    "    level_relations = {\n",
    "        'debug':logging.DEBUG,\n",
    "        'info':logging.INFO,\n",
    "        'warning':logging.WARNING,\n",
    "        'error':logging.ERROR,\n",
    "        'crit':logging.CRITICAL\n",
    "    }#日志级别关系映射\n",
    " \n",
    "    def __init__(self,filename,level='info',when='D',backCount=3,fmt='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'):\n",
    "        self.logger = logging.getLogger(filename)\n",
    "        format_str = logging.Formatter(fmt)#设置日志格式\n",
    "        self.logger.setLevel(self.level_relations.get(level))#设置日志级别\n",
    "        sh = logging.StreamHandler()#往屏幕上输出\n",
    "        sh.setFormatter(format_str) #设置屏幕上显示的格式\n",
    "        th = handlers.TimedRotatingFileHandler(filename=filename,when=when,backupCount=backCount,encoding='utf-8')#往文件里写入#指定间隔时间自动生成文件的处理器\n",
    "        #实例化TimedRotatingFileHandler\n",
    "        #interval是时间间隔，backupCount是备份文件的个数，如果超过这个个数，就会自动删除，when是间隔的时间单位，单位有以下几种：\n",
    "        # S 秒 M 分  H 小时、 D 天、 W 每星期（interval==0时代表星期一）\n",
    "        # midnight 每天凌晨\n",
    "        th.setFormatter(format_str)#设置文件里写入的格式\n",
    "        self.logger.addHandler(sh) #把对象加到logger里\n",
    "        self.logger.addHandler(th)\n",
    "if __name__ == '__main__':\n",
    "    log = Logger('all.log',level='debug')\n",
    "    log.logger.debug('debug')\n",
    "    log.logger.info('info')\n",
    "    log.logger.warning('警告')\n",
    "    log.logger.error('报错')\n",
    "    log.logger.critical('严重') \n",
    "\n",
    "# log = Logger('log/501_couplet.log',level='debug')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0814 11:16:40.479709 4321588096 <ipython-input-68-c2744b8de12c>:1] 我面试35\n",
      "NoneType: None\n"
     ]
    }
   ],
   "source": [
    "logging.exception(\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-14 11:19:26,251 - <ipython-input-69-6c8b667f265e>[line:33] - DEBUG: debug\n",
      "I0814 11:19:26.251430 4321588096 <ipython-input-69-6c8b667f265e>:33] debug\n",
      "2019-08-14 11:19:26,265 - <ipython-input-69-6c8b667f265e>[line:34] - INFO: info\n",
      "I0814 11:19:26.265645 4321588096 <ipython-input-69-6c8b667f265e>:34] info\n",
      "2019-08-14 11:19:26,270 - <ipython-input-69-6c8b667f265e>[line:35] - WARNING: 警告\n",
      "W0814 11:19:26.270969 4321588096 <ipython-input-69-6c8b667f265e>:35] 警告\n",
      "2019-08-14 11:19:26,275 - <ipython-input-69-6c8b667f265e>[line:36] - ERROR: 报错\n",
      "E0814 11:19:26.275985 4321588096 <ipython-input-69-6c8b667f265e>:36] 报错\n",
      "2019-08-14 11:19:26,280 - <ipython-input-69-6c8b667f265e>[line:37] - CRITICAL: 严重\n",
      "E0814 11:19:26.280014 4321588096 <ipython-input-69-6c8b667f265e>:37] CRITICAL - 严重\n",
      "2019-08-14 11:19:26,285 - <ipython-input-69-6c8b667f265e>[line:38] - ERROR: error\n",
      "E0814 11:19:26.285053 4321588096 <ipython-input-69-6c8b667f265e>:38] error\n"
     ]
    }
   ],
   "source": [
    "#     on_epoch_end: logs include `acc` and `loss`, and\n",
    "#         optionally include `val_loss`\n",
    "#         (if validation is enabled in `fit`), and `val_acc`\n",
    "#         (if validation and accuracy monitoring are enabled).\n",
    "#     on_batch_begin: logs include `size`,\n",
    "#         the number of samples in the current batch.\n",
    "#     on_batch_end: logs include `loss`, and optionally `acc`\n",
    "#         (if accuracy monitoring is enabled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
