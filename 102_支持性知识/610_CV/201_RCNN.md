# R-CNN

**2014年**



[博客原地址======](https://blog.csdn.net/briblue/article/details/82012575)



### 什么是目标检测

给定一张图片可以识别出类别就是，**对象识别**。

而**目标检测**除了要识别类别外，还要找到他们的位置。

显然，目标检测比对象识别更难。



### R-CNN 在前人的肩膀上前行

​	2012 年 Krizhevsky 等人在 ImageNet 举办的 ILSVRC 目标识别挑战大赛中一战成名，豪夺当年的第一名，Top5 错误率 15%,而他们团队提出来的网络结构以他们的导师名字命名，它就是 AlexNet。

它有 5 层卷积层,2 层全连接层。

因为 AlexNet 的出现，世人的目光重回神经网络领域，以此为契机，不断涌出各种各样的网络比如 VGG、GoogleNet、ResNet 等等。

受 AlexNet 启发，论文作者尝试将 AlexNet 在 ImageNet 目标识别的能力泛化到 PASCAL VOC 目标检测上面来。

但一切开始之前，需要解决两个主要的问题。

如何利用深度的神经网络去做目标的定位？
如何在一个小规模的数据集上训练能力强劲的网络模型？ 

### 利用候选区域与 CNN 结合做目标定位

借鉴了滑动窗口思想，R-CNN 采用对区域进行识别的方案。

具体是：

1. 给定一张输入图片，从图片中提取 2000 个类别独立的候选区域。
2. 对于每个区域利用 CNN 抽取一个固定长度的特征向量。
3. 再对每个区域利用 SVM 进行目标分类。



## 利用预训练与微调解决标注数据缺乏的问题

利用预训练与微调解决标注数据缺乏的问题

采用在 ImageNet 上已经训练好的模型，然后在 PASCAL VOC 数据集上进行 fine-tune。

因为 ImageNet 的图像高达几百万张，利用卷积神经网络充分学习浅层的特征，然后在小规模数据集做规模化训练，从而可以达到好的效果。

现在，我们称之为迁移学习，是必不可少的一种技能。

 

## R-CNN 的目标识别之路

前面内容提到过，R-CNN 系统分为 3 个阶段，反应到架构上由 3 个模块完成。

1. 生产类别独立的候选区域，这些候选区域其中包含了 R-CNN 最终定位的结果。
2. 神经网络去针对每个候选区域提取固定长度的特征向量。
3. 一系列的 SVM 分类器。



## 候选区域

能够生成候选区域的方法很多，比如：

objectness
selective search
category-independen object proposals
constrained parametric min-cuts(CPMC)
multi-scale combinatorial grouping
Ciresan
R-CNN 采用的是 Selective Search 算法。

## 特征抽取

R-CNN 抽取了一个 4096 维的特征向量，采用的是 Alexnet，基于 Caffe 进行代码开发。

需要注意的是 Alextnet 的输入图像大小是 227x227。

而通过 Selective Search 产生的候选区域大小不一，为了与 Alexnet 兼容，R-CNN 采用了非常暴力的手段，那就是无视候选区域的大小和形状，统一变换到 227*227 的尺寸。

有一个细节，在对 Region 进行变换的时候，首先对这些区域进行膨胀处理，在其 box 周围附加了 p 个像素，也就是人为添加了边框，在这里 p=16。 

## 测试阶段的目标检测

在测试阶段，R-CNN 在每张图片上抽取近 2000 个候选区域。

然后将每个候选区域进行尺寸的修整变换，送进神经网络以读取特征，然后用 SVM 进行类别的识别，并产生分数。

候选区域有 2000 个，所以很多会进行重叠。

针对每个类，通过计算 IoU 指标，采取非极大性抑制，以最高分的区域为基础，剔除掉那些重叠位置的区域。

## 训练

前面已经提到过 R-CNN 采取迁移学习。

提取在 ILSVRC 2012 的模型和权重，然后在 VOC 上进行 fine-tune。

需要注意的是，这里在 ImageNet 上训练的是模型识别物体类型的能力，而不是预测 bbox 位置的能力。

ImageNet 的训练当中需要预测 1000 个类别，而 R-CNN 在 VOC 上进行迁移学习时，神经网络只需要识别 21 个类别。这是 VOC 规定的 20 个类别加上背景这个类别。

R-CNN 将候选区域与 GroundTrue 中的 box 标签相比较，如果 IoU > 0.5，说明两个对象重叠的位置比较多，于是就可以认为这个候选区域是 Positive,否则就是 Negetive.

训练策略是：采用 SGD 训练，初始学习率为 0.001，mini-batch 大小为 128.

## 对象识别相关

通常对待一个二值化的分类器，它的结果只要 2 中，Positive 和 Negetive。

比如，有一个汽车分类器，它可以轻松地确认，一个方框里面包含了一辆汽车，那么它肯定就是 Positive。

也可以很清楚地确认，如果一个背景方框中没有包含汽车，那么它就是 Negetive。

**但是，比较难确认的是，如果一个方框，只有一部分与汽车重叠，那么如何标注这个方框呢？**

R-CNN 采用的是 IoU 的阈值，这个 threshold 取 0.3，如果一个区域与 Ground tureth 的 IoU 值低于设定的阈值，那么可以讲它看成是 Negetive.

IoU 的 threshold 它不是作者胡乱取值的，而是来自 {0,0.1,0.2,0.3,0.4,0.5} 的数值组合的。

而且，这个数值至关重要，如果 threshold 取值为 0.5,mAP 指标直接下降 5 个点，如果取值为 0，mAP 下降 4 个点。

一旦特征抽取成功，R-CNN 会用 SVM 去识别每个区域的类别，但这需要优化。

因为训练的数据太大，不可能一下子填充到电脑内存当中，R-CNN 作者采取了一种叫做 Hard negetive mining 的手段。

 