{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要内容\n",
    "- 数据预处理| 将原始数据转换成可作为模型输入的数值型特征，包 括数据标准化、离散化、特征编码等过程，也有的人将特征选择和 降维归并在数据预处理之中. 请时刻谨记 Grabage In, Garbage Out\n",
    "- 特征选择 | 从原始特征全集中选择与目标特征相关的特征子集. \n",
    "- 降维 | 减少特征数量的过程，包括特征选择和特征提取，这里特指通过降维算法将多个原始特征进行组合得到新特征的 特征提取过程，如主成分分析、线性判别分析等.\n",
    "- 特征学习 | 利用机器学习算法或模型自动抽取特征的过程，如自编 码器，并且大部分降维算法属于无监督特征学习算法."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "- 使用转换函数\n",
    "- 使用转换器接口 (Transformer API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# 方式一 使用转换函数\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方式二 使用转换器接口\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled_2 = scaler.transform(X)\n",
    "X_scaled_2[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化\n",
    "\n",
    "- StandardScaler  Z-score标准化\n",
    "- MinMaxScaler   最小化，最大化\n",
    "- MaxAbsScaler   稀疏数据标准化\n",
    "- RobustScaler\n",
    "- QuantileTransformer 带离群值的标准化\n",
    "- RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = preprocessing.StandardScaler()  # z = (x - u) / s\n",
    "scaler.fit(X)\n",
    "X_scaled_2 = scaler.transform(X)\n",
    "X_scaled_2[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()  # x/l1  or x/l2\n",
    "X_normal = scaler.fit_transform(X)\n",
    "X_normal[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0)\n",
    "X_bin = binarizer.fit_transform(X)\n",
    "X_bin[-3:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "X_encoder = encoder.fit_transform(X)\n",
    "X_encoder[:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_encoder = encoder.fit_transform(y)\n",
    "y_encoder[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据白化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多项式特征生成与自定义转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式特征生成\n",
    "\n",
    "- 基于特征集合{X1, X2}，将产生新的特征集合{1, X1, X2, X12, X1X2, X2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n",
      "(150, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  5.1 ,  3.5 , 26.01, 17.85, 12.25],\n",
       "       [ 1.  ,  4.9 ,  3.  , 24.01, 14.7 ,  9.  ],\n",
       "       [ 1.  ,  4.7 ,  3.2 , 22.09, 15.04, 10.24]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "x_cut = X[:,:2] \n",
    "print(x_cut.shape)\n",
    "x_poly = poly.fit_transform(x_cut)\n",
    "print(x_poly.shape)\n",
    "x_poly[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义转换\n",
    "- 将所有数据进行对数转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.80828877, 1.5040774 , 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.38629436, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.83290912, 0.18232156]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p)\n",
    "x_log = transformer.transform(X)\n",
    "x_log[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouwencheng/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_selection as fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤式（Filter）\n",
    "- 按照特征与目标特征的相关性对各个特征进行评分，设定阈值或者 待选择阈值的个数选择特征.\n",
    "- fs.VarianceThreshold(threshold) | 方差阈值过滤，去除 特征全集中方差较小的特征.\n",
    "- fs.SelectKBest(score_func, k) | 保留得分排名前k的特征 (top k方式).\n",
    "- fs.SelectPercentile(score_func, percentile) | 保留 得分排名前k%个特征(top k%方式)，即最终保留特征的比例为k%.\n",
    "\n",
    "### score_func\n",
    "- 分类问题\n",
    "    - 卡方检验 chi2    (假设验证 方法)\n",
    "    - ANOVA F 值 f_classif  (方差验证)\n",
    "    - 互信息 MI mutual_info_classid （互信息(Mutual Information)是度量两个事件集合之间的相关性）\n",
    "- 回归问题\n",
    "    - F检验值 f_regression\n",
    "    - 互信息MI mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2],\n",
       "       [4.6, 1.5, 0.2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold = VarianceThreshold(threshold=0.3)\n",
    "feature = threshold.fit_transform(X, y)\n",
    "feature[:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "best = SelectKBest(k = 2)\n",
    "x_best = best.fit_transform(X, y)\n",
    "x_best[:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "percentile = SelectPercentile(percentile = 0.1)\n",
    "x_percentile = percentile.fit_transform(X, y)\n",
    "x_percentile[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装式(Wrapper)\n",
    "    根据模型的评价指标，每次选择若干特征，或者排除若干特征，包 括序列向前搜索SFS、序列向后搜索SBS等搜索方法，特征选择与最 终的模型构建是两个独立的过程.\n",
    "- fs.RFE(estimator, n_features_to_select) | 递归特征消 除法，得到指定特征个数的特征子集.\n",
    "- fs.RFECV(estimator, scoring=”r2”) | 结合交􏰁验证的递 归特征消除法，得到特征子集的最优特征个数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "rfe = RFE(lr, 2)\n",
    "x_rfe = rfe.fit_transform(X, y) \n",
    "x_rfe[:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/zhouwencheng/Desktop/Grass/02Study/02PythonEnv/1env2/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logist = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "\n",
    "rfe = RFECV(logist, 2, cv=2)\n",
    "x_rfe = rfe.fit_transform(X, y) \n",
    "x_rfe[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入式 (Embedded)\n",
    "    使用某些机器学习的算法(带正则化的线性模型、决策树以􏰂基于 决策树的集成模型)和模型自动进行特征选择，特征选择与模型评 价融合在同一过程中.\n",
    "    \n",
    "- fs.SelectFromModel(estimator) | 从模型中自动选择特征， 任何具有coef_或者feature_importances_的基模型都可以作为estimator参数传入.\n",
    "\n",
    "### 基模型\n",
    "- linear_model.LogisticRegression \n",
    "- linear_model.LogisticRegressionCV\n",
    "- linear_model.Lasso\n",
    "- linear_model.LassoCV\n",
    "- svm.LinearSVC\n",
    "- svm.LinearSVR\n",
    "- ensemble.RandomForestRegressor\n",
    "- ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "enbeded = SelectFromModel(rfc)\n",
    "x_enbeded = enbeded.fit_transform(X, y)\n",
    "x_enbeded[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维（特征提取）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析 \n",
    "- 通过线性投影，将高维的数据映射到低维的空间中， 目标是最大化重构后方差."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68412563,  0.31939725],\n",
       "       [-2.71414169, -0.17700123],\n",
       "       [-2.88899057, -0.14494943],\n",
       "       [-2.74534286, -0.31829898]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(X)\n",
    "x_pca[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性判别分析\n",
    "- 利用数据的类别信息，将高维的样本线性投影到低 维空间中，使得数据样本在低维空间中的类别区分度最大，即使得 相同类样本尽可能近，不同类样本尽可能远."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.06179978,  0.30042062],\n",
       "       [ 7.12868772, -0.78666043],\n",
       "       [ 7.48982797, -0.26538449],\n",
       "       [ 6.81320057, -0.67063107]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "x_lda = lda.fit_transform(X, y)\n",
    "x_lda[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多维尺度变换\n",
    "- 找到数据的低维表示，使得降维前后样本之间的相 似度信息(如距离信息)尽量得以保留."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1912652 , -1.59850629],\n",
       "       [ 2.48353405, -1.14008232],\n",
       "       [ 2.59888068, -1.29897625],\n",
       "       [ 2.56760346, -1.05123381]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=2)\n",
    "x_mds = mds.fit_transform(X)\n",
    "x_mds[:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他降维方法\n",
    "\n",
    "- 核主成分分析 decomposition.KernelPCA \n",
    "- 局部线性映射 manifold.LocallyLinearEmbedding \n",
    "- 等度量映射 manifold.Isomap\n",
    "- t-SNE manifold.TSNE\n",
    "- 拉普拉斯映射 manifold.SpectralEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
