{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遍历文档树\n",
    "- 子节点\n",
    "- 父节点\n",
    "- 兄弟结点\n",
    "- 回退和前进\n",
    "- 搜索文档树\n",
    "- 过滤器\n",
    "- find_all\n",
    "- 像调用find_all一样调用tag\n",
    "- find\n",
    "- find_parents 和 find_parent\n",
    "- find_next_siblings() 和 find_next_sibling()\n",
    "- find_previous_siblings() 和 find_previous_siblingx\n",
    "- find_all_next() 和 find_next()\n",
    "- find_all_previous() 和 find_previous()\n",
    "- CSS选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "    <body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 子节点\n",
    "一个tag可能包含多个字符串或其他的Tag这些都是这个Tag节点子节点。Beautiful Soup提供了许多操作和遍历子节点的属性."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>The Dormouse's story</title></head>\n",
      "<title>The Dormouse's story</title>\n",
      "<b>The Dormouse's story</b>\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
      "The Dormouse's story\n",
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n",
      "\"The Dormouse's story\"\n",
      "\"The Dormouse's story\"\n",
      "'Once upon a time there were three little sisters; and their names were'\n",
      "'Elsie'\n",
      "','\n",
      "'Lacie'\n",
      "'and'\n",
      "'Tillie'\n",
      "';\\nand they lived at the bottom of a well.'\n",
      "'...'\n"
     ]
    }
   ],
   "source": [
    "#------------------- tag的名字\n",
    "\"\"\"\n",
    "操作文档树最简单的方法就是告诉它你想获取的tag的name.如果想获取 <head> 标签,只要用 soup.head :\n",
    "\"\"\"\n",
    "print(soup.head) # <head><title>The Dormouse's story</title></head>\n",
    "print(soup.title) # <title>The Dormouse's story</title>\n",
    "print(soup.body.b) # <b>The Dormouse's story</b>\n",
    "\n",
    "# 通过点取属性的方式只能获得当前名字的第一个tag:\n",
    "print(soup.a) # <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "print(soup.find_all('a'))\n",
    "\"\"\"\n",
    "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, \n",
    "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\"\"\"\n",
    "\n",
    "#------------------------- .contents 和 .children\n",
    "\"\"\"\n",
    "tag的 .contents 属性可以将tag的子节点以列表的方式输出:\n",
    "\n",
    "通过tag的 .children 生成器,可以对tag的子节点进行循环:\n",
    "\"\"\"\n",
    "head_tag = soup.head\n",
    "head_tag # <head><title>The Dormouse's story</title></head>\n",
    "\n",
    "head_tag.contents # [<title>The Dormouse's story</title>]\n",
    "title_tag = head_tag.contents[0] \n",
    "title_tag # <title>The Dormouse's story</title>\n",
    "title_tag.contents # [\"The Dormouse's story\"]\n",
    "\n",
    "\n",
    "for child in title_tag.children:\n",
    "    print(child)\n",
    "    # The Dormouse's story\n",
    "    \n",
    "    \n",
    "#--------------------- .descendants\n",
    "\"\"\" \n",
    "descendants 属性可以对所有tag的子孙节点进行递归循环 [5] :\n",
    "\n",
    "head_tag # <head><title>The Dormouse's story</title></head>\n",
    "\"\"\"\n",
    "for child in head_tag.descendants:\n",
    "    print(child)\n",
    "    # <title>The Dormouse's story</title>\n",
    "    # The Dormouse's story\n",
    "\n",
    "#----------------------------- .string\n",
    "\"\"\"\n",
    "如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点\n",
    "\"\"\"\n",
    "\n",
    "#----------------------------- .strings 和 stripped_strings\n",
    "\"\"\"\n",
    "如果tag中包含多个字符串 [2] ,可以使用 .strings 来循环获取:\n",
    "输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容:\n",
    "\"\"\"\n",
    "# for string in soup.strings:\n",
    "#     print(repr(string))\n",
    "\n",
    "# for string in soup.stripped_strings:\n",
    "#     print(repr(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 父节点\n",
    "继续分析文档树,每个tag或字符串都有父节点:被包含在某个tag中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "#----------------------- .parent\n",
    "\"\"\"\n",
    "通过 .parent 属性来获取某个元素的父节点.在例子“爱丽丝”的文档中,<head>标签是<title>标签的父节点:\n",
    "\"\"\"\n",
    "title_tag = soup.title\n",
    "title_tag\n",
    "# <title>The Dormouse's story</title>\n",
    "title_tag.parent\n",
    "# <head><title>The Dormouse's story</title></head>\n",
    "\n",
    "#---- 文档title的字符串也有父节点:<title>标签\n",
    "title_tag.string.parent\n",
    "# <title>The Dormouse's story</title>\n",
    "\n",
    "#-------------------------- .parents\n",
    "\"\"\"\n",
    "通过元素的 .parents 属性可以递归得到元素的所有父辈节点,下面的例子使用了\n",
    ".parents 方法遍历了<a>标签到根节点的所有节点.\n",
    "\"\"\"\n",
    "link = soup.a\n",
    "link\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "for parent in link.parents:\n",
    "    if parent is None:\n",
    "        print(parent)\n",
    "    else:\n",
    "        print(parent.name)\n",
    "\"\"\"\n",
    "p\n",
    "body\n",
    "html\n",
    "[document]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 兄弟结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "';\\nand they lived at the bottom of a well.'\n",
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "'Once upon a time there were three little sisters; and their names were\\n'\n"
     ]
    }
   ],
   "source": [
    "sibling_soup = BeautifulSoup(\"<a><b>text1</b><c>text2</c></a>\")\n",
    "# print(sibling_soup.prettify())\n",
    "\"\"\"\n",
    "因为<b>标签和<c>标签是同一层:他们是同一个元素的子节点,所以<b>和<c>可以被称为兄弟节点.\n",
    "\"\"\"\n",
    "\n",
    "#------------------------------------ .next_sibling 和 .previous_sibling\n",
    "sibling_soup.b.next_sibling\n",
    "# <c>text2</c>\n",
    "sibling_soup.c.previous_sibling\n",
    "# <b>text1</b>\n",
    "\n",
    "\"\"\"\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "\n",
    "如果以为第一个<a>标签的\n",
    ".next_sibling 结果是第二个<a>标签,那就错了,\n",
    "真实结果是第一个<a>标签和第二个<a>标签之间的顿号和换行符:\n",
    "\"\"\"\n",
    "link = soup.a\n",
    "link\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "link.next_sibling\n",
    "# ',\\n'\n",
    "link.next_sibling.next_sibling\n",
    "# <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
    "\n",
    "#------------------------------- .next_siblings 和 .previous_siblings\n",
    "for sibling in soup.a.next_siblings:\n",
    "    print(repr(sibling))\n",
    "\"\"\"\n",
    "',\\n'\n",
    "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
    "' and\\n'\n",
    "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
    "';\\nand they lived at the bottom of a well.'\n",
    "\"\"\"\n",
    "    \n",
    "for sibling in soup.find(id=\"link3\").previous_siblings:\n",
    "    print(repr(sibling))\n",
    "\"\"\"\n",
    "' and\\n'\n",
    "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
    "',\\n'\n",
    "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "'Once upon a time there were three little sisters; and their names were\\n'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 回退和前进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "看一下“爱丽丝” 文档:\n",
    "\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\"\"\"\n",
    "\n",
    "#----------------------------------- .next_element 和 .previous_element\n",
    "\"\"\"\n",
    ".next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),结果可能与 \n",
    ".next_sibling 相同,但通常是不一样的.\n",
    "\"\"\"\n",
    "#------------------------------------ .next_elements 和 .previous_elements\n",
    "\"\"\"\n",
    "通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,\n",
    "就好像文档正在被解析一样:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 搜索文档树\n",
    "Beautiful Soup定义了很多搜索方法,这里着重介绍2个: find() 和 find_all()\n",
    ".其它方法的参数和用法类似,请读者举一反三."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 过滤器\n",
    "介绍 find_all() 方法前,先介绍一下过滤器的类型 [3] ,这些过滤器贯穿整个搜索的API.过滤器可以被用在tag的name中,节点的属性中,字符串中或他们的混合中.\n",
    "\n",
    "- 字符串\n",
    "- 正则表达式\n",
    "- 列表\n",
    "- True\n",
    "- 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      "b\n",
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "p\n",
      "b\n",
      "p\n",
      "a\n",
      "a\n",
      "a\n",
      "p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
       " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>,\n",
       " <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------- 字符串\n",
    "\"\"\"\n",
    "最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,\n",
    "下面的例子用于查找文档中所有的<b>标签:\n",
    "\"\"\"\n",
    "soup.find_all('b')\n",
    "# [<b>The Dormouse's story</b>]\n",
    "\n",
    "#----------------------------------- 正则表达式\n",
    "\"\"\"\n",
    "如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.\n",
    "下面例子中找出所有以b开头的标签,这表示<body>和<b>标签都应该被找到:\n",
    "\"\"\"\n",
    "import re\n",
    "for tag in soup.find_all(re.compile(\"^b\")):\n",
    "    print(tag.name)\n",
    "\"\"\"\n",
    "body\n",
    "b\n",
    "\"\"\"\n",
    "    \n",
    "#----------------------------------- 列表\n",
    "\"\"\"\n",
    "如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.\n",
    "下面代码找到文档中所有<a>标签和<b>标签:\n",
    "\"\"\"\n",
    "soup.find_all([\"a\", \"b\"])\n",
    "\"\"\"\n",
    "[<b>The Dormouse's story</b>,\n",
    " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\"\"\"\n",
    "\n",
    "#----------------------------------- True\n",
    "\"\"\"\n",
    "True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\n",
    "\"\"\"\n",
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)\n",
    "\"\"\" \n",
    "html\n",
    "head\n",
    "title\n",
    "body\n",
    "p\n",
    "b\n",
    "p\n",
    "a\n",
    "a\n",
    "a\n",
    "p\n",
    "\"\"\" \n",
    "\n",
    "#---------------------------------- 方法\n",
    "\"\"\"\n",
    "如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 [4] ,\n",
    "如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n",
    "\"\"\"\n",
    "def has_class_but_no_id(tag):\n",
    "    return tag.has_attr('class') and not tag.has_attr('id')\n",
    "soup.find_all(has_class_but_no_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 find_all\n",
    "find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "soup.find_all(\"p\", \"title\")\n",
    "# [<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
    "\n",
    "soup.find_all(\"a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.find_all(id=\"link2\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "import re\n",
    "soup.find(string=re.compile(\"sisters\"))\n",
    "# u'Once upon a time there were three little sisters; and their names were\\n'\n",
    "\n",
    "#----------------------- name参数\n",
    "\"\"\"\n",
    "name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n",
    "\"\"\"\n",
    "soup.find_all(\"title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "\n",
    "#------------------------ keyword 参数\n",
    "\"\"\"\n",
    "如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,\n",
    "如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性.\n",
    "\"\"\"\n",
    "soup.find_all(id='link2')\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "soup.find_all(href=re.compile(\"elsie\"))\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.find_all(id=True)\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.find_all(href=re.compile(\"elsie\"), id='link1')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">three</a>]\n",
    "\n",
    "# data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>')\n",
    "# data_soup.find_all(data-foo=\"value\")\n",
    "# SyntaxError: keyword can't be an expression\n",
    "\n",
    "# data_soup.find_all(attrs={\"data-foo\": \"value\"})\n",
    "# # [<div data-foo=\"value\">foo!</div>]\n",
    "\n",
    "#----------------------- 按CSS搜索\n",
    "\"\"\"\n",
    "按照CSS类名搜索tag的功能非常实用,但标识CSS类名的关键字 class 在Python中是保留字,使用 class 做参数会导致语法错误.\n",
    "\n",
    "string 参数\n",
    "limit 参数\n",
    "recursive 参数\n",
    "\"\"\"\n",
    "soup.find_all(\"a\", class_=\"sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.find_all(class_=re.compile(\"itl\"))\n",
    "# [<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
    "\n",
    "def has_six_characters(css_class):\n",
    "    return css_class is not None and len(css_class) == 6\n",
    "soup.find_all(class_=has_six_characters)\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.find_all(string=\"Elsie\")\n",
    "# [u'Elsie']\n",
    "\n",
    "soup.find_all(string=[\"Tillie\", \"Elsie\", \"Lacie\"])\n",
    "# [u'Elsie', u'Lacie', u'Tillie']\n",
    "\n",
    "soup.find_all(string=re.compile(\"Dormouse\"))\n",
    "# [u\"The Dormouse's story\", u\"The Dormouse's story\"]\n",
    "\n",
    "soup.find_all(\"a\", limit=2)\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 像调用find_all一样调用tag\n",
    "find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 find\n",
    "find_all() 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 find_all() 方法来查找<body>标签就不太合适, 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法.下面两行代码是等价的:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 find_parents() 和 find_parent()\n",
    "我们已经用了很大篇幅来介绍 find_all() 和 find() 方法,Beautiful Soup中还有10个用于搜索的API.它们中的五个用的是与 find_all() 相同的搜索参数,另外5个与 find() 方法的搜索参数类似.区别仅是它们搜索文档的不同部分.\n",
    "\n",
    "- find_parents( name , attrs , recursive , string , **kwargs )\n",
    "- find_parent( name , attrs , recursive , string , **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string = soup.find(string=\"Lacie\")\n",
    "a_string\n",
    "# u'Lacie'\n",
    "\n",
    "a_string.find_parents(\"a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "a_string.find_parent(\"p\")\n",
    "# <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "#  <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
    "#  and they lived at the bottom of a well.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 find_next_siblings() 和 find_next_sibling()\n",
    "这2个方法通过 .next_siblings 属性对当tag的所有后面解析 [5] 的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.\n",
    "- find_next_siblings( name , attrs , recursive , string , **kwargs )\n",
    "- find_next_sibling( name , attrs , recursive , string , **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">...</p>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "\n",
    "first_link.find_next_siblings(\"a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "first_story_paragraph = soup.find(\"p\", \"story\")\n",
    "first_story_paragraph.find_next_sibling(\"p\")\n",
    "# <p class=\"story\">...</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 find_previous_siblings() 和 find_previous_siblingx\n",
    "这2个方法通过 .previous_siblings 属性对当前tag的前面解析 [5] 的兄弟tag节点进行迭代, find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:\n",
    "- find_previous_siblings( name , attrs , recursive , string , **kwargs )\n",
    "- find_previous_sibling( name , attrs , recursive , string , **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"title\"><b>The Dormouse's story</b></p>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link = soup.find(\"a\", id=\"link3\")\n",
    "last_link\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
    "\n",
    "last_link.find_previous_siblings(\"a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "first_story_paragraph = soup.find(\"p\", \"story\")\n",
    "first_story_paragraph.find_previous_sibling(\"p\")\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13  find_all_next() 和 find_next()\n",
    "这2个方法通过 .next_elements 属性对当前tag的之后的 [5] tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:\n",
    "- find_all_next( name , attrs , recursive , string , **kwargs )\n",
    "- find_next( name , attrs , recursive , string , **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">...</p>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "\n",
    "first_link.find_all_next(string=True)\n",
    "# [u'Elsie', u',\\n', u'Lacie', u' and\\n', u'Tillie',\n",
    "#  u';\\nand they lived at the bottom of a well.', u'\\n\\n', u'...', u'\\n']\n",
    "\n",
    "first_link.find_next(\"p\")\n",
    "# <p class=\"story\">...</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 find_all_previous() 和 find_previous()\n",
    "这2个方法通过 .previous_elements 属性对当前节点前面 [5] 的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.\n",
    "- find_all_previous( name , attrs , recursive , string , **kwargs )\n",
    "- find_previous( name , attrs , recursive , string , **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "\n",
    "first_link.find_all_previous(\"p\")\n",
    "# [<p class=\"story\">Once upon a time there were three little sisters; ...</p>,\n",
    "#  <p class=\"title\"><b>The Dormouse's story</b></p>]\n",
    "\n",
    "first_link.find_previous(\"title\")\n",
    "# <title>The Dormouse's story</title>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 CSS选择器\n",
    "Beautiful Soup支持大部分的CSS选择器 http://www.w3.org/TR/CSS2/selector.html [6] , 在 Tag 或 BeautifulSoup 对象的 .select() 方法中传入字符串参数, 即可使用CSS选择器的语法找到tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "soup.select(\"p:nth-of-type(3)\")\n",
    "# [<p class=\"story\">...</p>]\n",
    "\n",
    "#--------------------- 通过tag标签逐层查找:\n",
    "\n",
    "soup.select(\"body a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\"  id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"html head title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "#--------------------- 找到某个tag标签下的直接子标签\n",
    "soup.select(\"head > title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "soup.select(\"p > a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\"  id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"p > a:nth-of-type(2)\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "soup.select(\"p > #link1\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select(\"body > a\")\n",
    "# []\n",
    "\n",
    "#--------------------- 找到兄弟节点标签:\n",
    "soup.select(\"#link1 ~ .sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\"  id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"#link1 + .sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "#---------------------- 通过CSS的类名查找:\n",
    "\n",
    "soup.select(\".sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"[class~=sister]\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "#------------------------ 通过tag的id查找:\n",
    "soup.select(\"#link1\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select(\"a#link2\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "\n",
    "#---------------------------- 同时用多种CSS选择器查询元素:\n",
    "soup.select(\"#link1,#link2\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "#---------------------------- 通过是否存在某个属性来查找:\n",
    "soup.select('a[href]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "#----------------------------- 通过属性的值来查找:\n",
    "soup.select('a[href=\"http://example.com/elsie\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select('a[href^=\"http://example.com/\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select('a[href$=\"tillie\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select('a[href*=\".com/el\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "#---------------------------------- 通过语言设置来查找:\n",
    "multilingual_markup = \"\"\"\n",
    " <p lang=\"en\">Hello</p>\n",
    " <p lang=\"en-us\">Howdy, y'all</p>\n",
    " <p lang=\"en-gb\">Pip-pip, old fruit</p>\n",
    " <p lang=\"fr\">Bonjour mes amis</p>\n",
    "\"\"\"\n",
    "multilingual_soup = BeautifulSoup(multilingual_markup)\n",
    "multilingual_soup.select('p[lang|=en]')\n",
    "# [<p lang=\"en\">Hello</p>,\n",
    "#  <p lang=\"en-us\">Howdy, y'all</p>,\n",
    "#  <p lang=\"en-gb\">Pip-pip, old fruit</p>]\n",
    "\n",
    "#---------------------------------- 返回查找到的元素的第一个\n",
    "soup.select_one(\".sister\")\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
