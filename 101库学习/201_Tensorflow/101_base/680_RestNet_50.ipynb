{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "def resnet50(x, num_class=1000, is_training=True):\n",
    "    in_layer = x.get_shape()[-1]  # 获取输入的层数 \n",
    "        \n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape= [7, 7, in_layer, 64], stddev = 0.1))\n",
    "    conv_1 = tf.nn.conv2d(x, filters=W_conv1, strides=[1, 2, 2, 1], padding='same') # 112x112x64\n",
    "    nb_1 = tf.layers.batch_normalization(conv_1, axis=3, is_training=is_training) \n",
    "    relu_1 = tf.nn.relu(nb_1)\n",
    "    \n",
    "    maxpool_1 = tf.nn.max_pool(relu_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME') # 56x56x64\n",
    "    \n",
    "    block1 = block(maxpool_1, out_layer=256, repeat=3, stride=1, is_trainning=is_trainning, scope='block1')\n",
    "    block2 = block(block1, out_layer=512, repeat=4, stride=2, is_trainning=is_trainning, scope='block2')\n",
    "    block3 = block(block2, out_layer=1024, repeat=6, stride=2, is_trainning=is_trainning, scope='block3')\n",
    "    block4 = block(block3, out_layer=2048, repeat=3, stride=2, is_trainning=is_trainning, scope='block4')\n",
    "    \n",
    "    avgpool_1 = tf.nn.avg_pool(block4, ksize=[1, 7, 7, 1], strides=[1, 7, 7, 1], padding='SAME' )\n",
    "    \n",
    "    squeeze_1 = tf.squeeze(avgpool_1, [1, 2], name='SpatialSqueeze')\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal(shape = [2048, num_class], stddev = 0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape = [num_class]))\n",
    "    mul = tf.matmul(x, W) + b\n",
    "    \n",
    "    prediction = tf.nn.softmax(mul)\n",
    "    \n",
    "    return prediction\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def block(x, out_layer, repeat, stride=2, is_trainning=True, scope='block'):\n",
    "    with tf.variable_scope(scope):\n",
    "        start_layer = out_layer //4 # RestNet50每一层都是开始输入层数是输出层数的4倍\n",
    "        out = bottleneck(x, start_layer=start_layer, out_layer=out_layer, stride=stride, is_training=is_training, scope='bottlencek1')\n",
    "        for i in range(1, repeat):\n",
    "            out = bottleneck(out, start_layer=start_layer, out_layer=out_layer, stride=1, is_training=is_training, scope=('bottlencek1%ld'%(i+1)))\n",
    "        return out\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "x: 输入值\n",
    "start_layer : 开始层数\n",
    "out_layer: 输出层数\n",
    "stride: 步长\n",
    "is_training：批量褚思华是否训练\n",
    "\"\"\"\n",
    "\n",
    "def bottleneck(x, start_layer, out_layer, stride = None, is_training=True, scope='bottleneck'):\n",
    "    in_layer = x.shape[-1]  # 获取输入的层数\n",
    "    if stride is None: \n",
    "        \"\"\"\n",
    "        由于RestNet每个代码块只有两种情况 \n",
    "        第一种：同层之间(那么x图层的大小和输出的就一样的) (这种情况步长=1)\n",
    "        第二种：跨层，那么输出x图层大小就等于输入的一般（这种情况下）\n",
    "        \"\"\" \n",
    "        stride = 1 if in_layer==out_layer else 2  \n",
    "    with tf.variable_scope(scope):\n",
    "        W_conv1 = tf.Variable(tf.truncated_normal(shape= [1, 1, in_layer, start_layer], stddev = 0.1))\n",
    "        conv_1 = tf.nn.conv2d(x, filter=W_conv1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "        nb_1 = tf.layers.batch_normalization(conv_1, axis=3, training=is_training)\n",
    "        relu_1 = tf.nn.relu(conv_1)\n",
    "        \n",
    "        W_conv2 = tf.Variable(tf.truncated_normal(shape= [3, 3, start_layer, start_layer], stddev = 0.1))\n",
    "        conv_2 = tf.nn.conv2d(relu_1, filter=W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        nb_2 = tf.layers.batch_normalization(conv_2, axis=3, training=is_training)\n",
    "        relu_2 = tf.nn.relu(nb_2)\n",
    "        \n",
    "        W_conv3 = tf.Variable(tf.truncated_normal(shape= [3, 3, start_layer, out_layer], stddev = 0.1))\n",
    "        conv_3 = tf.nn.conv2d(relu_2, filter=W_conv3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        nb_3 = tf.layers.batch_normalization(conv_3, axis=3, training=is_training)\n",
    "    \n",
    "        if in_layer != out_layer:\n",
    "            W_short1 = tf.Variable(tf.truncated_normal(shape= [1, 1, in_layer, out_layer], stddev = 0.1))\n",
    "            conv_4 = tf.nn.conv2d(x, filter=W_short1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "            short_cut = tf.layers.batch_normalization(conv_4, axis=3, training=is_training)\n",
    "        else:\n",
    "            short_cut = x\n",
    "        return tf.nn.relu(short_cut + nb_3) \n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3e1a85549b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# predition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# bottleneck(x, 3, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# nb_1 = tf.layers.batch_normalization(x, training=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-93985fcd8fa8>\u001b[0m in \u001b[0;36mblock\u001b[0;34m(x, out_layer, repeat, stride, is_trainning, scope)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mstart_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_layer\u001b[0m \u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;31m# RestNet50每一层都是开始输入层数是输出层数的4倍\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bottlencek1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottlencek1%ld'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_training' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x = np.random.random([32, 224, 224, 3]) \n",
    "x = x.astype(np.float32)\n",
    "# predition = resnet50(x)\n",
    "# predition\n",
    "# bottleneck(x, 3, 64)\n",
    "block(x, 64, 3)\n",
    "# nb_1 = tf.layers.batch_normalization(x, training=True)\n",
    "\n",
    "# type(x[1][1][1][1])\n",
    "\n",
    "# x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
