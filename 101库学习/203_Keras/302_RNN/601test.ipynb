{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/zhouwencheng/Desktop/Grass/data/txt/letters/\"\n",
    "source_path= base_path+\"letters_source.txt\"\n",
    "target_path= base_path+\"letters_target.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(source_path) as f:\n",
    "    source_texts=f.read().split('\\n')\n",
    "with open(target_path) as f:\n",
    "    target_texts=f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_flag='<PAD>'\n",
    "unk_flag='<UNK>'\n",
    "start_flag='<GO>'\n",
    "end_flag='<EOS>'\n",
    "flag_list=[pad_flag, unk_flag, start_flag, end_flag]\n",
    "\n",
    "all_chars=list(set(\"\".join(source_texts)+\"\".join(target_texts)))\n",
    "all_chars=flag_list+sorted(all_chars)\n",
    "index_to_char={i:char for i, char in enumerate(all_chars)}\n",
    "char_to_index={char:i for i, char in enumerate(all_chars)}\n",
    "max_len_source=max([len(item) for item in source_texts])\n",
    "max_len_traget=max([len(item) for item in target_texts])\n",
    "\n",
    "\n",
    "pad_flag_index=char_to_index[pad_flag]\n",
    "unk_flag_index=char_to_index[unk_flag]\n",
    "start_flag_index=char_to_index[start_flag]\n",
    "end_flag_index=char_to_index[end_flag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad\n",
    "id_sources=[]\n",
    "for item in source_texts:\n",
    "    pad_len=max_len_source-len(item)\n",
    "    item_paded=[char_to_index.get(char, unk_flag_index)  for char in item]+[end_flag_index]+[pad_flag_index]*pad_len\n",
    "    id_sources.append(item_paded)\n",
    "id_target=[]\n",
    "for item in target_texts:\n",
    "    pad_len=max_len_traget-len(item)\n",
    "    item_paded=[start_flag_index]+[char_to_index.get(char, unk_flag_index)  for char in item]+[end_flag_index]+[pad_flag_index]*pad_len\n",
    "    id_target.append(item_paded)\n",
    "    \n",
    "vocab_len=len(index_to_char)\n",
    "source_input_len=max([len(item) for item in id_sources])\n",
    "traget_input_len=max([len(item) for item in id_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_enbeding\n",
    "z_target= np.zeros((len(id_target), traget_input_len, vocab_len))\n",
    "for i in range(len(id_target)):\n",
    "    item=id_target[i]  \n",
    "    for j in range(len(item)):\n",
    "        index=item[j] \n",
    "        z_target[i, j, index]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from seq2seq import AttentionSeq2Seq\n",
    "from keras.layers import Embedding, Dense, Activation, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab_size = vocab_len\n",
    "dec_vocab_size = vocab_len\n",
    "enc_input_length = source_input_len\n",
    "dec_output_length = traget_input_len\n",
    "enc_embedding_length = 36\n",
    "dec_embedding_length = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded.shape: (?, ?, 128)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_embedding (Embedding (None, 8, 36)             1080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 36)             144       \n",
      "_________________________________________________________________\n",
      "model_36 (Model)             (None, 9, 36)             442185    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 9, 30)             1110      \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 9, 30)             0         \n",
      "=================================================================\n",
      "Total params: 444,519\n",
      "Trainable params: 444,447\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(\n",
    "        vocab_len,\n",
    "        enc_embedding_length, \n",
    "        input_length=enc_input_length,\n",
    "        trainable=True,\n",
    "        name='encoder_embedding')\n",
    "enc_normalization = BatchNormalization()\n",
    "seq2seq = AttentionSeq2Seq(\n",
    "        bidirectional=False,\n",
    "        output_dim=dec_embedding_length, \n",
    "        hidden_dim=128, \n",
    "        output_length=dec_output_length, \n",
    "        input_shape=(enc_input_length, enc_embedding_length), \n",
    "        depth=2)\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(enc_normalization)\n",
    "model.add(seq2seq)\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(dec_vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0058 - acc: 0.8549\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 0.0052 - acc: 0.8704\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.0052 - acc: 0.8721\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 0.0049 - acc: 0.8824\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0046 - acc: 0.8898\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0043 - acc: 0.8984\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.0038 - acc: 0.9130\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.0037 - acc: 0.9147\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.0035 - acc: 0.9214\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.0031 - acc: 0.9316\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.0028 - acc: 0.9391\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.0027 - acc: 0.9414\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 0.0023 - acc: 0.9536\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0021 - acc: 0.9596\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.0018 - acc: 0.9656\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0016 - acc: 0.9709\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.0013 - acc: 0.9762\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 0.0013 - acc: 0.9769\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.0010 - acc: 0.9812\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 9.4825e-04 - acc: 0.9830\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.0010 - acc: 0.9814\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 7.4663e-04 - acc: 0.9867\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 8.8133e-04 - acc: 0.9836\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 6.3550e-04 - acc: 0.9885\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 6.7051e-04 - acc: 0.9878\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 6.0127e-04 - acc: 0.9888\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 5.6909e-04 - acc: 0.9895\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 6.0146e-04 - acc: 0.9889\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 5.2073e-04 - acc: 0.9904\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 4.4792e-04 - acc: 0.9915\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 5.7002e-04 - acc: 0.9893\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 3.9166e-04 - acc: 0.9928\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 5.1532e-04 - acc: 0.9905\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 4.6360e-04 - acc: 0.9914\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 2.7047e-04 - acc: 0.9952\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 28s 3ms/step - loss: 2.9577e-04 - acc: 0.9947\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 28s 3ms/step - loss: 5.0040e-04 - acc: 0.9907\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 3.9430e-04 - acc: 0.9927\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 2.8261e-04 - acc: 0.9947\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 4.2140e-04 - acc: 0.9923\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "model.load_weights('letter_model.h5')\n",
    "# model = load_model('letter_model.h5')\n",
    "\n",
    "id_sources=np.array(id_sources)\n",
    "id_target=np.array(id_target)\n",
    "\n",
    "model.fit(x=id_sources, y=z_target, batch_size=32, epochs=40)\n",
    "# model.save('letter_model.h5')\n",
    "model.save_weights(\"letter_model.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=\"a\"\n",
    "pad_len=max_len_source-len(test)\n",
    "item_paded=[char_to_index.get(char, unk_flag_index)  for char in test]+[end_flag_index]+[pad_flag_index]*pad_len\n",
    "test_id=[item_paded]\n",
    "test_id=np.array(test_id)\n",
    "test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>\n",
      "a\n",
      "<EOS>\n",
      "<PAD>\n",
      "<PAD>\n",
      "<PAD>\n",
      "<PAD>\n",
      "<PAD>\n",
      "<PAD>\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_on_batch(test_id)[0]\n",
    "prediction.shape\n",
    "for item in prediction:\n",
    "    idx = np.argmax(item, axis=0)\n",
    "    char = index_to_char.get(idx, unk_flag)\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x13aa262b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
